{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d8a6fd-d179-44ad-b6cd-a9914b7fb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# import keras\n",
    "# import tensorflow as tf\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "import importlib\n",
    "# import neural_networks as nn\n",
    "# import plotting as pl\n",
    "import utils\n",
    "\n",
    "import pyreadr\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef91a37-9dac-4ac5-a9de-e23407c60f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import feature name for plotting\n",
    "# feature_categories_DE = pyreadr.read_r('F:/PROJEKTE/FARM/Daten/Datenanalyse/ML/ml_code/output/useful/colors_feature_categories_DE.RDS')[None]\n",
    "# feature_categories_DE = pyreadr.read_r('../colors_feature_categories_ENG_update.RDS')[None]\n",
    "\n",
    "\n",
    "# feature_categories_DE.loc[feature_categories_DE.abbr=='other_nonagri_pu', 'short_name_feature'] = 'Sonst. nlw. Fl. m. pot. Pest.'\n",
    "# feature_categories_DE.loc[feature_categories_DE.abbr=='other_nonagri_wpu', 'short_name_feature'] = 'Sonst. nlw. Fl. o. pot. Pest.'\n",
    "# feature_categories_DE.loc[feature_categories_DE.abbr=='other_agri_pu', 'short_name_feature'] = 'Sonst. lw. Fl. m. pot. Pest.'\n",
    "# feature_categories_DE.loc[feature_categories_DE.abbr=='other_agri_wpu', 'short_name_feature'] = 'Sonst. lw. Fl. o. pot. Pest.'\n",
    "# feature_categories_DE.loc[feature_categories_DE.abbr=='other', 'short_name_feature'] = 'Sonst. nlw. Fl.'\n",
    "# # correct encoding\n",
    "# for col in feature_categories_DE.select_dtypes(['object']).columns:\n",
    "#     feature_categories_DE[col] = feature_categories_DE[col].str.replace('Ã¤', 'ä')\n",
    "#     feature_categories_DE[col] = feature_categories_DE[col].str.replace('Ã¼', 'ü')\n",
    "#     feature_categories_DE[col] = feature_categories_DE[col].str.replace('Ã¶', 'ö')\n",
    "#     feature_categories_DE[col] = feature_categories_DE[col].str.replace('ÃŸ', 'ß')\n",
    "# feature_categories_DE.head()\n",
    "# feature_dict = dict(feature_categories_DE.loc[:, ['feature', 'short_name_feature']].values)\n",
    "# feature_dict['Makroporen_rounded'] = 'Makroporenklasse'\n",
    "# feature_dict['arable_land_new'] = 'Ackerland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec4512d-48d9-4960-b67e-90120288388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red = pyreadr.read_r('../preprocessed_red_features_sentinel.RDS')[None]\n",
    "df_all = pyreadr.read_r('../preprocessed_red_features_sentinel.RDS')[None]\n",
    "# replace categorical strings by True/False for each category\n",
    "dummy_columns = df_red.select_dtypes(['object', 'category']).columns.drop(['lawa_name', 'messstellen_id', 'bundesland', 'messnetz', 'dt_name', 'engl_name', 'conc_group'])\n",
    "df_red_1hot = pd.get_dummies(df_red, columns=dummy_columns)\n",
    "dummy_columns = df_all.select_dtypes(['object', 'category']).columns.drop(['lawa_name', 'messstellen_id', 'bundesland', 'messnetz', 'dt_name', 'engl_name', 'conc_group'])\n",
    "df_all_1hot = pd.get_dummies(df_all, columns=dummy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05404706-7f12-43b6-81d0-e73c48457691",
   "metadata": {},
   "outputs": [],
   "source": [
    "prio_compounds = ['desphenyl-chloridazon', 'metazachlor esa', 'metazachlorsäure', 'methyl-desphenylchloridazon', 'metolachlor esa', 'metolachlor-ca', 's-metolachlor-metabolit noa 413173', 'trifluoressigsaeure']\n",
    "feature_selections = list('AC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3082b70e-f2f9-490b-8895-0039260c6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_from_cm(cm):\n",
    "    recall = np.diag(cm) / np.sum(cm, axis=1)\n",
    "    precision = np.diag(cm) / np.sum(cm, axis=0)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3114bcd3-5e3d-42ef-916a-c45a10bd97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_sids = {\n",
    "    'desphenyl-chloridazon': [14, 16], \n",
    "    'metazachlor esa': [12, 16, 20], # 23 \n",
    "    'metazachlorsäure': [12, 16, 20], # 23\n",
    "    'methyl-desphenylchloridazon': [14, 16], \n",
    "    'metolachlor esa': [7, 9, 10, 17, 19], # 27 \n",
    "    'metolachlor-ca': [7, 9, 10, 17, 19], # 27 \n",
    "    's-metolachlor-metabolit noa 413173': [7, 9, 10, 17, 19], # 27 \n",
    "    'trifluoressigsaeure': [1, 2, 3, 4, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] # 22, 23, 24, 25, 26, 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b3d3e42-a89a-4f69-928b-a4a5119663a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "n_folds = 5 # outer folds\n",
    "n_outer_folds = 5\n",
    "i_ini = 0\n",
    "n_ini = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f055f-e1a1-4cb3-9c06-689270410c13",
   "metadata": {},
   "source": [
    "### compare performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebd42d-89db-4713-9b8f-c1e04c7c90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = len(prio_compounds)\n",
    "f, axs = plt.subplots(2, int(nc/2), figsize=(3*nc/2, 6), sharey=True)\n",
    "# ax.set_xticks()\n",
    "folder_name='18_2classesMTOcorrection'\n",
    "n_classes=2\n",
    "feature_selections=list('AC')\n",
    "for i, compound_name in enumerate(prio_compounds[:]):\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.set_xticks(range(len(feature_selections)), ['reduziert', 'alle'])\n",
    "    # ax.set_xticks(range(len(feature_selections)), feature_selections)\n",
    "    ax.set_xlim(-.5, len(feature_selections)-.5)\n",
    "    ax.set_title(compound_name.title(), fontdict={'fontsize':10})\n",
    "\n",
    "    for j, feature_selection in enumerate(feature_selections):\n",
    "        \n",
    "        output_folder = f'F:/PROJEKTE/FARM/Ephraim_Erkens/bgr-grwv/develoments_BGR/EE/output/nestedCV/{folder_name}/{compound_name}/feature_selection_{feature_selection}/'\n",
    "        cm_stacked = np.zeros((n_classes, n_classes))\n",
    "\n",
    "        try:\n",
    "            performances = pd.read_csv(output_folder + 'performances.csv')\n",
    "            for fold in range(n_folds):\n",
    "                cm = pd.read_csv(output_folder + f'data/cm_stacked_outerFold_outerFold{fold}.csv', index_col=0)\n",
    "                cm_stacked += cm.values\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        f1 = performances[performances.test_set=='outer'].f1_tuned\n",
    "        mean_f1 = f1.mean()\n",
    "        ax.scatter(j, mean_f1, marker='s', s=30, label='Durchschnitt')\n",
    "        ax.scatter([j]*len(f1), f1, color='k', marker='.', label='Outer Folds')\n",
    "        f1_cm = f1_from_cm(cm_stacked)\n",
    "        # ax.scatter(j, f1_cm, marker='o', fc='none', ec='k', s=50, label='from cm')\n",
    "\n",
    "axs[0, 0].set_ylabel('F1-Score')\n",
    "axs[1, 0].set_ylabel('F1-Score')\n",
    "# axs[0, 2].set_xlabel('Feature-Auswahl', x=0)\n",
    "axs[1, 2].set_xlabel('Feature-Auswahl', x=0)\n",
    "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "axs[0, 0].legend(handles[:2], labels[:2], loc='lower right')\n",
    "\n",
    "f.subplots_adjust(wspace=0.0, hspace=.3)\n",
    "for ax in axs.flatten():\n",
    "    ax.grid(alpha=.2)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "f.suptitle('Performance FNN Nested Cross-Validation (2 Klassen)')\n",
    "f.savefig(f'F:/PROJEKTE/FARM/Ephraim_Erkens/bgr-grwv/develoments_BGR/EE/output/nestedCV/{folder_name}/f1Scores_allCompounds.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd365b4-4d60-4d2d-9eb9-34c074da9123",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c1bed-a16b-41fa-ba57-5a849ff10c7f",
   "metadata": {},
   "source": [
    "### compare performances (3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7724647d-738a-4c75-874b-7657daa86dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = len(prio_compounds)\n",
    "f, axs = plt.subplots(2, int(nc/2), figsize=(3*nc/2, 6), sharey=True)\n",
    "# ax.set_xticks()\n",
    "\n",
    "folder_name='19_3classesMTOcorrection'\n",
    "feature_selections = list('AC')\n",
    "n_classes=3\n",
    "\n",
    "for i, compound_name in enumerate(prio_compounds[:]):\n",
    "    ax = axs.flatten()[i]\n",
    "    # ax.set_xticks(range(len(feature_selections)), feature_selections)\n",
    "    ax.set_xticks(range(len(feature_selections)), ['reduziert', 'alle'])\n",
    "    ax.set_xlim(-.5, len(feature_selections)-.5)\n",
    "    ax.set_title(compound_name.title(), fontdict={'fontsize':10})\n",
    "\n",
    "    for j, feature_selection in enumerate(feature_selections[:]):\n",
    "        \n",
    "        output_folder = f'F:/PROJEKTE/FARM/Ephraim_Erkens/bgr-grwv/develoments_BGR/EE/output/nestedCV/{folder_name}/{compound_name}/feature_selection_{feature_selection}/'\n",
    "        cm_stacked = np.zeros((n_classes, n_classes))\n",
    "        \n",
    "        try:\n",
    "            performances = pd.read_csv(output_folder + 'performances.csv')\n",
    "            for fold in range(n_folds):\n",
    "                cm = pd.read_csv(output_folder + f'data/cm_stacked_outerFold_outerFold{fold}.csv', index_col=0)\n",
    "                cm_stacked += cm.values\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        f1 = performances[performances.test_set=='outer'].f1_tuned\n",
    "        mean_f1 = f1.mean()\n",
    "        ax.scatter(j, mean_f1, marker='s', s=30, label='Durchschnitt')\n",
    "        ax.scatter([j]*len(f1), f1, color='k', marker='.', label='Outer Folds')\n",
    "        f1_cm = f1_from_cm(cm_stacked)\n",
    "        # ax.scatter(j, f1_cm, marker='o', fc='none', ec='k', s=50, label='from cm')\n",
    "        \n",
    "        \n",
    "\n",
    "axs[0, 0].set_ylabel('F1-Score')\n",
    "axs[1, 0].set_ylabel('F1-Score')\n",
    "# axs[0, 2].set_xlabel('Feature-Auswahl', x=0)\n",
    "axs[1, 2].set_xlabel('Feature-Auswahl', x=0)\n",
    "handles, labels = axs[-1, -1].get_legend_handles_labels()\n",
    "axs[0, 0].legend(handles[:2], labels[:2], loc='lower right')\n",
    "\n",
    "f.subplots_adjust(wspace=0.0, hspace=.3)\n",
    "for ax in axs.flatten():\n",
    "    ax.grid(alpha=.2)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "f.suptitle('Performance FNN Nested Cross-Validation (3 Klassen)')\n",
    "# f.savefig(f'F:/PROJEKTE/FARM/Ephraim_Erkens/bgr-grwv/develoments_BGR/EE/output/nestedCV/{folder_name}/f1Scores_allCompounds.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e645ac-757d-43d8-8074-f00cd86e8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot comparison for TFA\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "model_names = ['07_cleanOutput']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a58b4a6-a082-4355-9b81-b6bd916663c1",
   "metadata": {},
   "source": [
    "### plot performance bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcfb2c-7b79-46a7-b12d-9cf98ba74674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder_name='19_3classesMTOcorrection'\n",
    "feature_selections = list('AC')\n",
    "n_classes=3\n",
    "for i, compound_name in enumerate(prio_compounds[:]):\n",
    "\n",
    "    for feature_selection in feature_selections:\n",
    "        skip=False\n",
    "        output_folder = f'F:/PROJEKTE/FARM/Ephraim_Erkens/bgr-grwv/develoments_BGR/EE/output/nestedCV/{folder_name}/{compound_name}/feature_selection_{feature_selection}/'\n",
    "        cm_stacked = np.zeros((n_classes, n_classes))\n",
    "        for fold in range(n_folds):\n",
    "            # cm = np.load(output_folder + f'models/cm_nCV_outerFold{fold}.npy')\n",
    "            try:\n",
    "                cm = pd.read_csv(output_folder + f'data/cm_stacked_outerFold_outerFold{fold}.csv', index_col=0)\n",
    "                cm_stacked += cm.values\n",
    "            except FileNotFoundError:\n",
    "                skip=True\n",
    "                continue\n",
    "        if skip:\n",
    "            print(compound_name, 'not found')\n",
    "            continue\n",
    "        print(compound_name, feature_selection)\n",
    "        f, ax = plt.subplots(figsize=(3,6), dpi=150)\n",
    "        pl.plot_classes_stacked(cm_stacked, from_cm=True, ax=ax, show=False, class_boundaries=[0.1, 1])\n",
    "        f.savefig(output_folder+'fig/performance_barPlotStacked.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        out_data = pd.DataFrame(cm_stacked, index=[f'{i_class+1}_true' for i_class in range(n_classes)], columns=[f'{i_class+1}_pred' for i_class in range(n_classes)])\n",
    "        out_data.to_csv(output_folder+'data/cm_stacked.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d5d5ae-2d8e-4bfc-90fb-4fcbd27c47d5",
   "metadata": {},
   "source": [
    "### plot permutation importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc264756-ee5c-4f3c-b18d-9a8e12bae88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = df_all.columns[~df_all.columns.isin(df_all_1hot.columns)]\n",
    "values = df_all_1hot.columns[~df_all_1hot.columns.isin(df_all.columns)]\n",
    "category_dict = {key:[] for key in keys}\n",
    "for key in keys:\n",
    "    for value in values:\n",
    "        if key in value:\n",
    "            category_dict[key].append(value)\n",
    "all_catFeatures = [feature for sublist in category_dict.values() for feature in sublist]\n",
    "inv_category_dict = {}\n",
    "for k in category_dict.keys():\n",
    "    for v in category_dict[k]:\n",
    "        inv_category_dict[v]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ad1076-76a8-42e6-ba95-e970adac6181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importlib.reload(utils)\n",
    "importlib.reload(pl)\n",
    "\n",
    "folder_name = '19_2classesMTOcorrection'\n",
    "feature_selections = list('AC')\n",
    "n_classes = 3\n",
    "\n",
    "\n",
    "n_features_ = 20\n",
    "\n",
    "shrink_factor=2 # for plot dimensions\n",
    "\n",
    "for i, compound_name in enumerate(prio_compounds[:]):\n",
    "    \n",
    "    for feature_selection in feature_selections:\n",
    "        print('feature selection:', feature_selection)\n",
    "        \n",
    "        output_folder = f'F:/PROJEKTE/FARM/Ephraim_Erkens/bgr-grwv/develoments_BGR/EE/output/nestedCV/{folder_name}/{compound_name}/feature_selection_{feature_selection}/'\n",
    " \n",
    "        try:\n",
    "            feature_names = list(np.load(f'{output_folder}data/feature_names.npy', allow_pickle=True))\n",
    "            fi = pd.read_csv(f'{output_folder}data/permutation_importance_{compound_name}.csv') # feature importance\n",
    "        except FileNotFoundError:\n",
    "            print(compound_name, 'not found')\n",
    "            continue\n",
    "        fi = fi.groupby('lawa_name').mean().reset_index().drop(columns=['outer_fold', 'lawa_name', 'initialization']) # mean of all folds\n",
    "        fi = fi.T.rename(columns={0:'importance'}) # transpose\n",
    "        fi['feature'] = fi.index\n",
    "        # fi = fi.drop('SD_1')\n",
    "        if n_classes==2:\n",
    "            fi = fi.drop('threshold')\n",
    "        elif n_classes==3:\n",
    "            fi = fi.drop('threshold1')\n",
    "            fi = fi.drop('threshold2')\n",
    "            fi = fi.drop('threshold3')\n",
    "        fi['is_categorical'] = ~fi.feature.isin(df_all.columns)\n",
    "        fi.loc[fi.is_categorical, 'feature_name'] = fi.feature.map(inv_category_dict)\n",
    "        fi.loc[~fi.is_categorical, 'feature_name'] = fi.feature\n",
    "        n_features = n_features_ if len(fi.feature_name.unique())>n_features_ else len(fi.feature_name.unique())\n",
    "        \n",
    "        y_min = -1.5/shrink_factor\n",
    "        y_max = n_features-0.5/shrink_factor\n",
    "        f, ax = plt.subplots(dpi=100, figsize=(4, n_features/shrink_factor))\n",
    "        pl.plot_permutation_importance(fi, ax=ax, n_features=n_features)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_title(compound_name)\n",
    "    \n",
    "        f.savefig(f'{output_folder}fig/permutationImportance_{compound_name}_{feature_selection}.png', bbox_inches='tight')\n",
    "        # plt.close()\n",
    "        print(compound_name)\n",
    "        # plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e7b75-d457-4809-9d9a-e53dfec4819c",
   "metadata": {},
   "source": [
    "### Plot partial dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0418cb6-6761-4873-a8a2-82e68898514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prio_compounds = ['desphenyl-chloridazon', 'metazachlor esa', 'metazachlorsäure', 'methyl-desphenylchloridazon', \n",
    "# 'metolachlor esa', 'metolachlor-ca', 's-metolachlor-metabolit noa 413173', 'trifluoressigsaeure']\n",
    "# prio_compounds = ['metolachlor-ca',]\n",
    "prio_compounds = ['trifluoressigsaeure']\n",
    "\n",
    "feature_selections = ['A']\n",
    "\n",
    "n_outer_folds = 5\n",
    "grid_resolution = 100\n",
    "\n",
    "# folder_name = '07_cleanOutput'\n",
    "# output_folder = f'F:/PROJEKTE/FARM/Ephraim_Erkens/bgr-grwv/develoments_BGR/EE/output/nestedCV/{folder_name}/{compound_name}/feature_selection_{feature_selection}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcc97b9-b1a8-4f7a-9a8f-da990d988cfc",
   "metadata": {},
   "source": [
    "#### 2 classes, single plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00c5c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a93aa4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = np.load(f'../data/feature_names.npy', allow_pickle=True)\n",
    "# feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5aad72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_name = prio_compounds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dff5da2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['filter_ok_unter_gok', 'sand_depth_weighted_mean',\n",
       "       'corg_gehalt_depth_weighted_mean', 'gwn_mean',\n",
       "       'area_sentinel_id_1', 'area_sentinel_id_2', 'area_sentinel_id_3',\n",
       "       'area_sentinel_id_4', 'area_sentinel_id_7', 'area_sentinel_id_9',\n",
       "       'area_sentinel_id_10', 'area_sentinel_id_12',\n",
       "       'area_sentinel_id_13', 'area_sentinel_id_14',\n",
       "       'area_sentinel_id_15', 'area_sentinel_id_16',\n",
       "       'area_sentinel_id_17', 'area_sentinel_id_18',\n",
       "       'area_sentinel_id_19', 'area_sentinel_id_20',\n",
       "       'area_sentinel_id_21', 'Makroporen_rounded_1',\n",
       "       'Makroporen_rounded_2', 'Makroporen_rounded_3', 'HA_K', 'HA_K/Ka',\n",
       "       'HA_K/P', 'HA_P', 'kf_bez_1', 'kf_bez_2', 'kf_bez_3'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = np.load(f'../13_paper2classes/{prio_compounds[0]}/feature_selection_A/data/feature_names.npy', allow_pickle=True)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4724f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i_feature, feature in enumerate(feature_names):\n",
    "#     print(feature)\n",
    "#     for outer_fold_index in range(5):\n",
    "#         print(f\"Outer fold index {outer_fold_index}\")\n",
    "#         X_train = np.load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/X_outer_train_nCV_outerFold{outer_fold_index}.npy')\n",
    "#         scaler = load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/StdScaler_outerFold{outer_fold_index}.bin')\n",
    "\n",
    "#         # ax.plot(x[:, outer_fold_index], 1-y.mean(axis=0)[:, outer_fold_index], 'cornflowerblue', linewidth=.5)\n",
    "\n",
    "#         dummy_df = pd.DataFrame(columns=feature_names)\n",
    "#         dummy_df[feature] = X_train[:, i_feature]\n",
    "#         print(X_train[:, i_feature].shape)\n",
    "#         x_inv_trans = scaler.inverse_transform(dummy_df)\n",
    "#         x_dataPoints = x_inv_trans[:, i_feature]\n",
    "\n",
    "#         # if i_feature == 0:\n",
    "#         #     # print(dummy_df)\n",
    "#         #     print(x_inv_trans.shape)\n",
    "#         #     print(x_dataPoints.shape)\n",
    "#         #     print(x[:, outer_fold_index].shape)\n",
    "#         #     print(y.mean(axis=0)[:, outer_fold_index].shape)\n",
    "#         #     break\n",
    "#     # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cc1c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/x_Pdp_{compound_name}_{feature.replace('/', '_')}.npy')\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a542442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/y_Pdp_{compound_name}_{feature.replace('/', '_')}.npy')\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88b2b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name_dict = {  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba94867-5db3-4200-a287-1ed03f1494fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'cornflowerblue' #'.3'\n",
    "\n",
    "correct_soc = True\n",
    "if correct_soc:\n",
    "    scale = 1.72**2\n",
    "else:\n",
    "    scale = 1\n",
    "\n",
    "for compound_name in prio_compounds:\n",
    "    # print(compound_name)\n",
    "    for feature_selection in feature_selections:\n",
    "        # print(feature_selection)\n",
    "        output_folder = f'../output/'\n",
    "        feature_names = np.load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/feature_names.npy', allow_pickle=True)\n",
    "        # print(feature_names)\n",
    "        if feature_selection == 'A':\n",
    "            keys = df_red.columns[~df_red.columns.isin(df_red_1hot.columns)]\n",
    "            values = df_red_1hot.columns[~df_red_1hot.columns.isin(df_red.columns)]\n",
    "        if feature_selection == 'C':\n",
    "            keys = df_all.columns[~df_all.columns.isin(df_all_1hot.columns)]\n",
    "            values = df_all_1hot.columns[~df_all_1hot.columns.isin(df_all.columns)]\n",
    "        category_dict = {key:[] for key in keys}\n",
    "        for key in keys:\n",
    "            for value in values:\n",
    "                if key in value:\n",
    "                    category_dict[key].append(value)\n",
    "        all_catFeatures = [feature for sublist in category_dict.values() for feature in sublist]\n",
    "        inv_category_dict = {}\n",
    "        for k in category_dict.keys():\n",
    "            for v in category_dict[k]:\n",
    "                inv_category_dict[v]=k            \n",
    "        for i_feature, feature in enumerate(feature_names):\n",
    "            if feature == 'area_sentinel_id_19':\n",
    "                continue\n",
    "\n",
    "            if feature != 'corg_gehalt_depth_weighted_mean':\n",
    "                continue\n",
    "            # print()\n",
    "            print(feature + \" is being processed.\")\n",
    "            if feature in all_catFeatures:\n",
    "                is_categorical=True\n",
    "            else:\n",
    "                is_categorical=False\n",
    "        \n",
    "\n",
    "            if not is_categorical:\n",
    "                # print(\"    not categorical\")\n",
    "                # x = np.load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/x_Pdp_{compound_name}_{feature.replace('/', '_')}.npy')\n",
    "                x = np.load(f\"../13_paper2classes/{compound_name}/feature_selection_A/data/x_Pdp_{compound_name}_{(feature.replace('/', '_'))}.npy\")\n",
    "                # y = np.load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/y_Pdp_{compound_name}_{feature.replace('/', '_')}.npy')\n",
    "                y = np.load(f\"../13_paper2classes/{compound_name}/feature_selection_A/data/y_Pdp_{compound_name}_{(feature.replace('/', '_'))}.npy\")\n",
    "\n",
    "                print(x.shape, y.shape)\n",
    "    \n",
    "                f, axs = plt.subplots(1, 2, figsize=(5, 4), dpi=200)\n",
    "                ax = axs[0]\n",
    "                for outer_fold_index in range(n_outer_folds):\n",
    "\n",
    "                    X_train = np.load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/X_outer_train_nCV_outerFold{outer_fold_index}.npy')\n",
    "                    scaler = load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/StdScaler_outerFold{outer_fold_index}.bin')\n",
    "\n",
    "                    ax.plot(x[:, outer_fold_index]/scale, 1-y.mean(axis=0)[:, outer_fold_index], 'cornflowerblue', linewidth=.5)\n",
    "\n",
    "                    dummy_df = pd.DataFrame(columns=feature_names)\n",
    "                    dummy_df[feature] = X_train[:, i_feature]\n",
    "                    x_inv_trans = scaler.inverse_transform(dummy_df)\n",
    "\n",
    "                    x_dataPoints = x_inv_trans[:, i_feature]\n",
    "                    # ax.vlines(x_dataPoints, 0, 0.04, color='blue', alpha=.025,)\n",
    "                    # axs[1].vlines(x_dataPoints, 0, 0.04, color='blue', alpha=.025)\n",
    "\n",
    "                ax.plot(x.mean(axis=1)/scale, 1-y.mean(axis=0).mean(axis=1), 'navy', zorder=10)\n",
    "                \n",
    "                try:\n",
    "                    xlabel = feature_dict[feature]\n",
    "                except KeyError:\n",
    "                    xlabel = feature\n",
    "                print('-', xlabel)\n",
    "                ax.set_xlabel(xlabel)\n",
    "                ax.set_title('Class 1', fontdict={'fontsize':10})\n",
    "                # ax.set_ylabel('probability', fontsize=10) # not needed\n",
    "                    \n",
    "                ax = axs[1]\n",
    "                for outer_fold_index in range(n_outer_folds):\n",
    "                    X_train = np.load(f'../13_paper2classes/{compound_name}/feature_selection_A/data/X_outer_train_nCV_outerFold{outer_fold_index}.npy')\n",
    "                    ax.plot(x[:, outer_fold_index]/scale, y.mean(axis=0)[:, outer_fold_index], 'cornflowerblue', linewidth=.5, label='Folds')\n",
    "                    # ax.vlines(X_train[:, i_feature], 0, 0.04, color='green', alpha=.1)\n",
    "                \n",
    "                ax.plot(x.mean(axis=1)/scale, y.mean(axis=0).mean(axis=1), 'navy', zorder=10, label='Average')\n",
    "                ax.set_xlabel(xlabel)\n",
    "                # ax.set_ylabel('blabla', fontsize=10) # Does not appear good. Overlaps with previous plot.\n",
    "\n",
    "                ax.set_title('Class 2', fontdict={'fontsize':10})\n",
    "                handles, labels = ax.get_legend_handles_labels()\n",
    "                ax.legend(handles[-2:], labels[-2:], frameon=True)\n",
    "\n",
    "                for ax in axs:\n",
    "                    ax.set_ylim(0,1)\n",
    "                    ax.grid(alpha=.3)\n",
    "                    ax.set_axisbelow(True)\n",
    "                # f.suptitle(compound_name.title(), y=1)\n",
    "                # f.savefig(f'../output/Pdp_{compound_name}_{feature.replace('/', '_')}.png', bbox_inches='tight')\n",
    "                if correct_soc:\n",
    "                    f.savefig(f\"../output_SOC/Pdp_{compound_name}_{(feature.replace('/', '_'))}.png\", bbox_inches='tight')\n",
    "                else:\n",
    "                    f.savefig(f\"../output/Pdp_{compound_name}_{(feature.replace('/', '_'))}.png\", bbox_inches='tight')\n",
    "                plt.close()\n",
    "                # plt.show()\n",
    "\n",
    "            if is_categorical:\n",
    "                print(\"categorical\")\n",
    "                original_feature = inv_category_dict[feature]\n",
    "                # print(feature, original_feature)\n",
    "                cat_feats = category_dict[original_feature]\n",
    "                n_1hot = len(cat_feats)\n",
    "                xticks = {cat_feat: i for i, cat_feat in enumerate(cat_feats)}\n",
    "                if xticks[feature] == 0:\n",
    "                    f, axs = plt.subplots(1, 2, figsize=(5, 4), dpi=200)\n",
    "\n",
    "                cat = [c.replace(f'{original_feature}_', '') for c in cat_feats]\n",
    "                try:\n",
    "                    xlabel = feature_dict[original_feature]\n",
    "                except KeyError:\n",
    "                    # xlabel = original_feature\n",
    "                    xlabel = feature_dict[original_feature]\n",
    "                print('-', xlabel)\n",
    "                for ax in axs:\n",
    "                    ax.set_xticks(list(xticks.values()), cat)\n",
    "                    ax.set_xticks(list(xticks.values()), cat)\n",
    "                    ax.set_xlim(-.5, n_1hot-.5)\n",
    "                    ax.set_xlabel(xlabel)\n",
    "                    \n",
    "                x = np.load(f\"../13_paper2classes/{compound_name}/feature_selection_A/data/x_Pdp_{compound_name}_{feature.replace('/', '_')}.npy\")\n",
    "                y = np.load(f\"../13_paper2classes/{compound_name}/feature_selection_A/data/y_Pdp_{compound_name}_{feature.replace('/', '_')}.npy\")\n",
    "\n",
    "                axs[0].bar(xticks[feature], 1- y[1, :].mean(), color=color)\n",
    "                axs[1].bar(xticks[feature], y[1, :].mean(), color=color)\n",
    "\n",
    "                axs[0].set_title('Class 1', fontdict={'fontsize':10})\n",
    "                axs[1].set_title('Class 2', fontdict={'fontsize':10})\n",
    "                \n",
    "                for ax in axs:\n",
    "                    ax.set_ylim(0,1)\n",
    "                    ax.grid(alpha=.3)\n",
    "                    ax.set_axisbelow(True)\n",
    "\n",
    "                if xticks[feature] == n_1hot-1:\n",
    "                    # f.suptitle(compound_name.title(), y=1)\n",
    "                    f.savefig(f\"../output/Pdp_{compound_name}_{original_feature.replace('/', '_')}.png\", bbox_inches='tight')\n",
    "                    \n",
    "                    plt.close()\n",
    "                    # plt.show()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543e2a3-323e-4f0a-87be-376731acfdc0",
   "metadata": {},
   "source": [
    "#### 2 classes, common plot (If you plot the features together!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abc654-ba82-4de7-8f6c-6ec3c74b7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '13_paper2classes'\n",
    "color = 'cornflowerblue' #'.3'\n",
    "feature_selections = list('A')\n",
    "\n",
    "for compound_name in prio_compounds[:]:\n",
    "    print(compound_name)\n",
    "    if (compound_name in ['metolachlor esa', 'metolachlor-ca', 's-metolachlor-metabolit noa 413173']):\n",
    "        continue\n",
    "    for feature_selection in feature_selections[:]:\n",
    "        count = 0\n",
    "        print('  ', feature_selection)\n",
    "        # output_folder = f'F:/PROJEKTE/FARM/Ephraim_Erkens/bgr-grwv/develoments_BGR/EE/output/nestedCV/{folder_name}/{compound_name}/feature_selection_{feature_selection}/'\n",
    "        feature_names = np.load(f\"../{folder_name}/{compound_name}/feature_selection_{feature_selection}/data/feature_names.npy\", allow_pickle=True)\n",
    "\n",
    "        if feature_selection == 'A':\n",
    "            keys = df_red.columns[~df_red.columns.isin(df_red_1hot.columns)]\n",
    "            values = df_red_1hot.columns[~df_red_1hot.columns.isin(df_red.columns)]\n",
    "            n_features = len(df_red.columns.drop(['lawa_name', 'messstellen_id', 'bundesland', 'messnetz', 'dt_name', 'engl_name', 'conc_group', 'x', 'y'])) - df_red.columns.str.contains('area_sentinel').sum() + len(relevant_sids[compound_name])\n",
    "            \n",
    "        if feature_selection == 'C':\n",
    "            keys = df_all.columns[~df_all.columns.isin(df_all_1hot.columns)]\n",
    "            values = df_all_1hot.columns[~df_all_1hot.columns.isin(df_all.columns)]\n",
    "            n_features = len(df_all.columns.drop(['lawa_name', 'messstellen_id', 'bundesland', 'messnetz', 'dt_name', 'engl_name', 'conc_group', 'x', 'y', 'arable_land_new'])) - df_all.columns.str.contains('area_sentinel').sum() + len(relevant_sids[compound_name])\n",
    "            \n",
    "        category_dict = {key:[] for key in keys}\n",
    "        for key in keys:\n",
    "            for value in values:\n",
    "                if key in value:\n",
    "                    category_dict[key].append(value)\n",
    "        all_catFeatures = [feature for sublist in category_dict.values() for feature in sublist]\n",
    "        inv_category_dict = {}\n",
    "        for k in category_dict.keys():\n",
    "            for v in category_dict[k]:\n",
    "                inv_category_dict[v]=k\n",
    "\n",
    "\n",
    "        n_cols = 4\n",
    "        n_rows = math.ceil(n_features/n_cols)\n",
    "        f, axs = plt.subplots(nrows=n_rows, ncols=n_cols*3, gridspec_kw={'width_ratios':[5, 5, .5]*n_cols}, figsize=(5*(n_cols+.1), 4*n_rows))\n",
    "\n",
    "        axf = axs.flatten()\n",
    "        # for i, ax in enumerate(axf):\n",
    "        #     ax.set_title(i)\n",
    "        \n",
    "        for i_feature, feature in enumerate(feature_names):\n",
    "            # print('    ', feature)\n",
    "            if feature in all_catFeatures:\n",
    "                is_categorical=True\n",
    "            else:\n",
    "                is_categorical=False\n",
    "\n",
    "\n",
    "            if not is_categorical:\n",
    "                x = np.load(f\"../13_paper2classes/{compound_name}/data/x_Pdp_{compound_name}_{feature.replace('/', '_')}.npy\")\n",
    "                y = np.load(f\"../13_paper2classes/{compound_name}/data/y_Pdp_{compound_name}_{feature.replace('/', '_')}.npy\")\n",
    "    \n",
    "                ax = axf[count*3]\n",
    "                for outer_fold_index in range(n_outer_folds):\n",
    "                    X_train = np.load(f'../data/X_outer_train_nCV_outerFold{outer_fold_index}.npy')\n",
    "                    scaler = load(f'../data/StdScaler_outerFold{outer_fold_index}.bin')\n",
    "                    xplot = x[:, outer_fold_index]\n",
    "                    yplot = 1-y.mean(axis=0)[:, outer_fold_index]\n",
    "                    # mask = xplot>1e-10\n",
    "                    # mask[0] = True\n",
    "                    index_lastData = np.where(xplot>1e-10)[0][-1]\n",
    "                    ax.plot(xplot[:index_lastData+1], yplot[:index_lastData+1], '.6', linewidth=.5)\n",
    "                    dummy_df = pd.DataFrame(columns=feature_names)\n",
    "                    dummy_df[feature] = X_train[:, i_feature]\n",
    "                    x_inv_trans = scaler.inverse_transform(dummy_df)\n",
    "                    x_dataPoints = x_inv_trans[:, i_feature]\n",
    "                    ax.vlines(x_dataPoints, 0, 0.04, color='k', alpha=.025)\n",
    "                    axf[count*3+1].vlines(x_dataPoints, 0, 0.04, color='k', alpha=.025)\n",
    "                ax.plot(x.mean(axis=1)[:index_lastData+1], 1-y.mean(axis=0).mean(axis=1)[:index_lastData+1], color, zorder=10)\n",
    "                try:\n",
    "                    xlabel = feature_dict[feature]\n",
    "                except KeyError:\n",
    "                    xlabel = feature\n",
    "                axf[count*3].set_xlabel(xlabel)\n",
    "                axf[count*3+1].set_xlabel(xlabel)\n",
    "                ax.set_title('Klasse 1', fontdict={'fontsize':10})\n",
    "                ax.set_ylabel('Vorhergesagte Wahrscheinlichkeit')\n",
    "                    \n",
    "                ax = axf[count*3+1]\n",
    "                for outer_fold_index in range(n_outer_folds):\n",
    "                    xplot = x[:, outer_fold_index]\n",
    "                    yplot = y.mean(axis=0)[:, outer_fold_index]\n",
    "                    index_lastData = np.where(xplot>1e-10)[0][-1]\n",
    "                    ax.plot(xplot[:index_lastData+1], yplot[:index_lastData+1], '.6', linewidth=.5, label='Folds')\n",
    "                    ax.vlines(X_train[:, i_feature], 0, 0.04, color='k', alpha=.1)\n",
    "                ax.plot(x.mean(axis=1)[:index_lastData+1], y.mean(axis=0).mean(axis=1)[:index_lastData+1], color, zorder=10, label='Durchschnitt')\n",
    "                ax.set_xlabel(xlabel)\n",
    "                ax.set_title('Klasse 2', fontdict={'fontsize':10})\n",
    "\n",
    "                handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            if is_categorical:\n",
    "                original_feature = inv_category_dict[feature]\n",
    "                # print(feature, original_feature)\n",
    "                cat_feats = category_dict[original_feature]\n",
    "                n_1hot = len(cat_feats)\n",
    "                xticks = {cat_feat: i for i, cat_feat in enumerate(cat_feats)}\n",
    "\n",
    "                x = np.load(f\"{output_folder}data/x_Pdp_{compound_name}_{feature.replace('/', '_')}.npy\")\n",
    "                y = np.load(f\"{output_folder}data/y_Pdp_{compound_name}_{feature.replace('/', '_')}.npy\")\n",
    "\n",
    "                cat = [c.replace(f'{original_feature}_', '') for c in cat_feats]\n",
    "                try:\n",
    "                    xlabel = feature_dict[original_feature]\n",
    "                except KeyError:\n",
    "                    xlabel = original_feature\n",
    "                    \n",
    "                ax = axf[count*3]\n",
    "                ax.set_xlabel(xlabel)\n",
    "                ax.set_xticks(list(xticks.values()), cat)\n",
    "                ax.set_xticks(list(xticks.values()), cat)\n",
    "                ax.set_xlim(-.5, n_1hot-.5)\n",
    "                ax.set_xlabel(xlabel)\n",
    "                ax.bar(xticks[feature], 1- y[1, :].mean(), color=color)\n",
    "                ax.set_title('Klasse 1', fontdict={'fontsize':10})\n",
    "                ax.set_ylabel('Vorhergesagte Wahrscheinlichkeit')\n",
    "                \n",
    "                \n",
    "                ax = axf[count*3+1]\n",
    "                ax.set_xlabel(xlabel)\n",
    "                ax.set_xticks(list(xticks.values()), cat)\n",
    "                ax.set_xticks(list(xticks.values()), cat)\n",
    "                ax.set_xlim(-.5, n_1hot-.5)\n",
    "                ax.set_xlabel(xlabel)\n",
    "                ax.bar(xticks[feature], y[1, :].mean(), color=color)\n",
    "                ax.set_title('Klasse 2', fontdict={'fontsize':10})\n",
    "                \n",
    "                \n",
    "                if xticks[feature] == n_1hot-1:\n",
    "                    count += 1\n",
    "\n",
    "        ax.legend(handles[-2:], labels[-2:], frameon=True, bbox_to_anchor=(1.2, 1), loc='upper left')\n",
    "\n",
    "        for i, ax in enumerate(axf):\n",
    "            ax.set_ylim(0,1)\n",
    "            ax.grid(alpha=.3)\n",
    "            ax.set_axisbelow(True)\n",
    "            if ((i+1)%3==0) | (i>=n_features*3):\n",
    "                f.delaxes(ax)\n",
    "        f.subplots_adjust(wspace=.4, hspace=.35)\n",
    "        f.suptitle(compound_name.title(), y=.9) if feature_selection=='C' else f.suptitle(compound_name.title(), y=.95)\n",
    "        f.savefig(f\"{output_folder}fig/pdp/Pdp_{compound_name}.png', bbox_inches='tight\")   \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2e1eb-d46c-4997-be38-e9985e029f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dend-proj",
   "language": "python",
   "name": "dend_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
