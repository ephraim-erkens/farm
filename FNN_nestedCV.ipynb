{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066a1a8-77dc-4822-a615-60d01a97749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import pyreadr\n",
    "# import shap\n",
    "# import glob\n",
    "# import seaborn as sns\n",
    "# import math\n",
    "# import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# scaling and train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # creating a model\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "# from tensorflow.keras.optimizers import Adam, SGD\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# from tensorflow.keras import regularizers\n",
    "# from tensorflow.keras import layers, models\n",
    "# from tensorflow.keras.metrics import Precision, Recall, Accuracy, BinaryAccuracy, CategoricalAccuracy, FalsePositives, FalseNegatives\n",
    "\n",
    "# evaluation on test data\n",
    "# from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import neural_networks as nn\n",
    "import importlib\n",
    "\n",
    "pd.set_option('display.max.columns', 150)\n",
    "pd.set_option('display.max.rows', 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db26ef6-b6d0-4e3a-a52c-01b4d88a6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red = pyreadr.read_r('F:/PROJEKTE/FARM/Daten/Datenanalyse/ML/data/spatial_features_all_compounds/preprocessed_red_features_sentinel.RDS')[None] # reduced features\n",
    "df_all = pyreadr.read_r('F:/PROJEKTE/FARM/Daten/Datenanalyse/ML/data/spatial_features_all_compounds/preprocessed_all_features_sentinel.RDS')[None] # all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4744ac6-1b12-427c-8801-8394be7b9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different data for TFA with class boundaries 0.1 and 1 ug/L:\n",
    "# df_red = pyreadr.read_r('F:/PROJEKTE/FARM/Daten/Datenanalyse/ML/data/spatial_features_all_compounds/preprocessed_red_features_sentinel_TFA.RDS')[None]\n",
    "# df_all = pyreadr.read_r('F:/PROJEKTE/FARM/Daten/Datenanalyse/ML/data/spatial_features_all_compounds/preprocessed_all_features_sentinel_TFA.RDS')[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e8fa2-7f83-4a02-a840-7217d7711e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct encoding\n",
    "for col in df_red.select_dtypes(['object', 'category']).columns:\n",
    "    df_red[col] = df_red[col].str.replace('Ã¤', 'ä')\n",
    "    df_red[col] = df_red[col].str.replace('Ã¼', 'ü')\n",
    "    df_red[col] = df_red[col].str.replace('Ã¶', 'ö')\n",
    "    df_red[col] = df_red[col].str.replace('ÃŸ', 'ß')\n",
    "\n",
    "for col in df_all.select_dtypes(['object', 'category']).columns:\n",
    "    df_all[col] = df_all[col].str.replace('Ã¤', 'ä')\n",
    "    df_all[col] = df_all[col].str.replace('Ã¼', 'ü')\n",
    "    df_all[col] = df_all[col].str.replace('Ã¶', 'ö')\n",
    "    df_all[col] = df_all[col].str.replace('ÃŸ', 'ß')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5dae395-1df0-40d9-9946-12f65447285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter messnetz for model for paper\n",
    "# df_all = df_all[df_all.messnetz=='Landesmessnetz']\n",
    "# df_red = df_red[df_red.messnetz=='Landesmessnetz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de6fe8-597b-4015-a8ff-edc837754c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### drop rows with missing conc_group\n",
    "\n",
    "df_red = df_red[~df_red.conc_group.isna()]\n",
    "df_red.conc_group = df_red.conc_group.astype('int')\n",
    "\n",
    "df_all = df_all[~df_all.conc_group.isna()]\n",
    "df_all.conc_group = df_all.conc_group.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "535948eb-0d45-4584-955b-2f17d91750b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### select number of classes\n",
    "n_classes = 2\n",
    "if n_classes == 2:\n",
    "    dfr = df_red.copy()\n",
    "    dfr.loc[(dfr.lawa_name!='trifluoressigsaeure') & (dfr.conc_group==3), 'conc_group'] = 2\n",
    "    dfr.loc[(dfr.lawa_name=='trifluoressigsaeure') & (dfr.conc_group==2), 'conc_group'] = 1\n",
    "    dfr.loc[(dfr.lawa_name=='trifluoressigsaeure') & (dfr.conc_group==3), 'conc_group'] = 2\n",
    "elif n_classes == 3:\n",
    "    dfr = df_red.copy()\n",
    "\n",
    "if n_classes == 2:\n",
    "    dfa = df_all.copy()\n",
    "    dfa.loc[(dfa.lawa_name!='trifluoressigsaeure') & (dfa.conc_group==3), 'conc_group'] = 2\n",
    "    dfa.loc[(dfa.lawa_name=='trifluoressigsaeure') & (dfa.conc_group==2), 'conc_group'] = 1\n",
    "    dfa.loc[(dfa.lawa_name=='trifluoressigsaeure') & (dfa.conc_group==3), 'conc_group'] = 2\n",
    "elif n_classes == 3:\n",
    "    dfa = df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717efe34-20e6-4625-9d11-e12a433e0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### select prioritary compounds\n",
    "prio_compounds = ['desphenyl-chloridazon', 'metazachlor esa', 'metazachlorsäure', 'methyl-desphenylchloridazon', 'metolachlor esa', 'metolachlor-ca', 's-metolachlor-metabolit noa 413173', 'trifluoressigsaeure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be41eb-0a5d-4883-b695-3ba5f06a0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define crops (sentinel ids) for which the compound / parent of the metabolites is applied\n",
    "relevant_sids = {\n",
    "    'desphenyl-chloridazon': [14, 16], \n",
    "    'metazachlor esa': [12, 16, 20], \n",
    "    'metazachlorsäure': [12, 16, 20],\n",
    "    'methyl-desphenylchloridazon': [14, 16], \n",
    "    'metolachlor esa': [7, 9, 10], \n",
    "    'metolachlor-ca': [7, 9, 10], \n",
    "    's-metolachlor-metabolit noa 413173': [7, 9, 10], \n",
    "    'trifluoressigsaeure': [1, 2, 3, 4, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8a8a9-2586-46f7-a9a9-2989bd87a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature selection\n",
    "# feature selection A: process-oriented features (=reduced features)\n",
    "fs_a = ['filter_ok_unter_gok', 'sand_depth_weighted_mean', 'corg_gehalt_depth_weighted_mean', 'Makroporen_rounded', 'gwn_mean', 'HA', 'kf_bez'] \n",
    "# + relevant areas\n",
    "\n",
    "# feature selection B: # not used anymore\n",
    "fs_b = fs_a + ['GR_NR', 'airtemp_mean_mean_Decade_2010_2019', 'mean_precip_summer', 'mean_precip_winter', 'precip_ratio_as_om', 'elevation_elevation_1KMmd', 'slope_slope_1KMmd', 'GA', 'GC', 'DSD_1', 'DSD_2', 'LP_1', 'LP_2', 'SD_1', 'SD_2', 'schluff_depth_weighted_mean', 'ton_depth_weighted_mean', 'swr_mean'] \n",
    "# + all areas\n",
    "\n",
    "# feature selection C: # (=all features)\n",
    "fs_c = fs_b + ['mean_nitrat', 'mean_ammonium', 'mean_magnesium', 'mean_sulfat', 'mean_chlorid', 'mean_kalium', 'mean_natrium', 'arable_land_new']\n",
    "\n",
    "feature_selections = ['A', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9fe44-2dfe-480d-b3d0-ad3c92667972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of model runs: 630\n"
     ]
    }
   ],
   "source": [
    "### set parameters for nested cross-validation\n",
    "folder_name = '18_2classesMTOcorrection' # output folder\n",
    "\n",
    "# number of folds\n",
    "n_inner_folds = 5\n",
    "n_outer_folds = 5\n",
    "\n",
    "# hyperparameter space (example)\n",
    "batch_size = [512, 1024]\n",
    "max_epochs = [500, 1000]\n",
    "hyperparameter = dict(batch_size=batch_size, max_epochs=max_epochs)\n",
    "\n",
    "# calculate number of runs\n",
    "n_runs = (n_inner_folds * n_outer_folds * len(batch_size) * len(max_epochs) + n_outer_folds) * len(feature_selections) * len(prio_compounds)\n",
    "print('number of model runs:', n_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f46b5-bdb4-47b2-bbc2-aa1affe3a2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ************************************************** \n",
      "\n",
      " METOLACHLOR ESA \n",
      "\n",
      "feature_selection: A\n",
      "relevant areas: ['area_sentinel_id_7', 'area_sentinel_id_9', 'area_sentinel_id_10']\n",
      "shape of feature matrix: (8757, 17)\n",
      "Thu Dec 12 08:57:24 2024 1/630 outer fold 0\n",
      "Thu Dec 12 08:57:24 2024 1/630   batch size 512\n",
      "Thu Dec 12 08:57:24 2024 1/630   max_epochs 500\n",
      "Thu Dec 12 08:57:24 2024 1/630     inner fold 0\n",
      "Thu Dec 12 08:58:23 2024 2/630     inner fold 1\n",
      "Thu Dec 12 08:58:42 2024 3/630     inner fold 2\n",
      "Thu Dec 12 08:59:40 2024 4/630     inner fold 3\n",
      "Thu Dec 12 09:00:04 2024 5/630     inner fold 4 f1_tuned: 0.711\n",
      "Thu Dec 12 09:00:30 2024 6/630   batch size 512\n",
      "Thu Dec 12 09:00:30 2024 6/630   max_epochs 1000\n",
      "Thu Dec 12 09:00:30 2024 6/630     inner fold 0\n",
      "Thu Dec 12 09:01:38 2024 7/630     inner fold 1\n",
      "Thu Dec 12 09:02:00 2024 8/630     inner fold 2\n",
      "Thu Dec 12 09:03:58 2024 9/630     inner fold 3\n",
      "Thu Dec 12 09:04:21 2024 10/630     inner fold 4 f1_tuned: 0.712\n",
      "Thu Dec 12 09:04:46 2024 11/630   batch size 1024\n",
      "Thu Dec 12 09:04:46 2024 11/630   max_epochs 500\n",
      "Thu Dec 12 09:04:46 2024 11/630     inner fold 0\n",
      "Thu Dec 12 09:05:23 2024 12/630     inner fold 1\n",
      "Thu Dec 12 09:05:48 2024 13/630     inner fold 2\n",
      "Thu Dec 12 09:06:24 2024 14/630     inner fold 3\n",
      "Thu Dec 12 09:06:55 2024 15/630     inner fold 4 f1_tuned: 0.709\n",
      "Thu Dec 12 09:07:28 2024 16/630   batch size 1024\n",
      "Thu Dec 12 09:07:28 2024 16/630   max_epochs 1000\n",
      "Thu Dec 12 09:07:28 2024 16/630     inner fold 0\n",
      "Thu Dec 12 09:09:31 2024 17/630     inner fold 1\n",
      "Thu Dec 12 09:10:00 2024 18/630     inner fold 2\n",
      "Thu Dec 12 09:10:49 2024 19/630     inner fold 3\n",
      "Thu Dec 12 09:11:19 2024 20/630     inner fold 4 f1_tuned: 0.711\n",
      "Thu Dec 12 09:12:00 2024 21/630   outer fold 0 with tuned HP f1_tuned: 0.706\n",
      "Thu Dec 12 09:12:50 2024 22/630 outer fold 1\n",
      "Thu Dec 12 09:12:50 2024 22/630   batch size 512\n",
      "Thu Dec 12 09:12:50 2024 22/630   max_epochs 500\n",
      "Thu Dec 12 09:12:50 2024 22/630     inner fold 0\n",
      "Thu Dec 12 09:13:10 2024 23/630     inner fold 1\n",
      "Thu Dec 12 09:14:09 2024 24/630     inner fold 2\n",
      "Thu Dec 12 09:14:29 2024 25/630     inner fold 3\n",
      "Thu Dec 12 09:15:28 2024 26/630     inner fold 4 f1_tuned: 0.709\n",
      "Thu Dec 12 09:15:49 2024 27/630   batch size 512\n",
      "Thu Dec 12 09:15:49 2024 27/630   max_epochs 1000\n",
      "Thu Dec 12 09:15:49 2024 27/630     inner fold 0\n",
      "Thu Dec 12 09:16:09 2024 28/630     inner fold 1\n",
      "Thu Dec 12 09:16:28 2024 29/630     inner fold 2\n",
      "Thu Dec 12 09:16:50 2024 30/630     inner fold 3\n",
      "Thu Dec 12 09:17:11 2024 31/630     inner fold 4 f1_tuned: 0.709\n",
      "Thu Dec 12 09:19:06 2024 32/630   batch size 1024\n",
      "Thu Dec 12 09:19:06 2024 32/630   max_epochs 500\n",
      "Thu Dec 12 09:19:06 2024 32/630     inner fold 0\n",
      "Thu Dec 12 09:19:37 2024 33/630     inner fold 1\n",
      "Thu Dec 12 09:20:19 2024 34/630     inner fold 2\n",
      "Thu Dec 12 09:20:53 2024 35/630     inner fold 3\n",
      "Thu Dec 12 09:21:34 2024 36/630     inner fold 4 f1_tuned: 0.711\n",
      "Thu Dec 12 09:22:10 2024 37/630   batch size 1024\n",
      "Thu Dec 12 09:22:10 2024 37/630   max_epochs 1000\n",
      "Thu Dec 12 09:22:10 2024 37/630     inner fold 0\n",
      "Thu Dec 12 09:22:41 2024 38/630     inner fold 1\n",
      "Thu Dec 12 09:23:48 2024 39/630     inner fold 2\n",
      "Thu Dec 12 09:24:16 2024 40/630     inner fold 3\n",
      "Thu Dec 12 09:24:50 2024 41/630     inner fold 4 f1_tuned: 0.708\n",
      "Thu Dec 12 09:25:28 2024 42/630   outer fold 1 with tuned HP f1_tuned: 0.703\n",
      "Thu Dec 12 09:25:54 2024 43/630 outer fold 2\n",
      "Thu Dec 12 09:25:54 2024 43/630   batch size 512\n",
      "Thu Dec 12 09:25:54 2024 43/630   max_epochs 500\n",
      "Thu Dec 12 09:25:54 2024 43/630     inner fold 0\n",
      "Thu Dec 12 09:26:53 2024 44/630     inner fold 1\n",
      "Thu Dec 12 09:27:52 2024 45/630     inner fold 2\n",
      "Thu Dec 12 09:28:52 2024 46/630     inner fold 3\n",
      "Thu Dec 12 09:29:11 2024 47/630     inner fold 4 f1_tuned: 0.709\n",
      "Thu Dec 12 09:29:44 2024 48/630   batch size 512\n",
      "Thu Dec 12 09:29:44 2024 48/630   max_epochs 1000\n",
      "Thu Dec 12 09:29:44 2024 48/630     inner fold 0\n",
      "Thu Dec 12 09:30:09 2024 49/630     inner fold 1\n",
      "Thu Dec 12 09:31:52 2024 50/630     inner fold 2\n",
      "Thu Dec 12 09:33:39 2024 51/630     inner fold 3\n",
      "Thu Dec 12 09:35:34 2024 52/630     inner fold 4 f1_tuned: 0.709\n",
      "Thu Dec 12 09:35:55 2024 53/630   batch size 1024\n",
      "Thu Dec 12 09:35:55 2024 53/630   max_epochs 500\n",
      "Thu Dec 12 09:35:55 2024 53/630     inner fold 0\n",
      "Thu Dec 12 09:36:24 2024 54/630     inner fold 1\n",
      "Thu Dec 12 09:37:25 2024 55/630     inner fold 2\n",
      "Thu Dec 12 09:38:12 2024 56/630     inner fold 3\n",
      "Thu Dec 12 09:38:36 2024 57/630     inner fold 4 f1_tuned: 0.706\n",
      "Thu Dec 12 09:39:04 2024 58/630   batch size 1024\n",
      "Thu Dec 12 09:39:04 2024 58/630   max_epochs 1000\n",
      "Thu Dec 12 09:39:04 2024 58/630     inner fold 0\n",
      "Thu Dec 12 09:39:32 2024 59/630     inner fold 1\n",
      "Thu Dec 12 09:40:52 2024 60/630     inner fold 2\n",
      "Thu Dec 12 09:41:24 2024 61/630     inner fold 3\n",
      "Thu Dec 12 09:42:07 2024 62/630     inner fold 4 f1_tuned: 0.708\n",
      "Thu Dec 12 09:42:48 2024 63/630   outer fold 2 with tuned HP f1_tuned: 0.722\n",
      "Thu Dec 12 09:44:02 2024 64/630 outer fold 3\n",
      "Thu Dec 12 09:44:02 2024 64/630   batch size 512\n",
      "Thu Dec 12 09:44:02 2024 64/630   max_epochs 500\n",
      "Thu Dec 12 09:44:02 2024 64/630     inner fold 0\n",
      "Thu Dec 12 09:45:08 2024 65/630     inner fold 1\n",
      "Thu Dec 12 09:45:43 2024 66/630     inner fold 2\n",
      "Thu Dec 12 09:46:50 2024 67/630     inner fold 3\n",
      "Thu Dec 12 09:47:13 2024 68/630     inner fold 4 f1_tuned: 0.715\n",
      "Thu Dec 12 09:47:34 2024 69/630   batch size 512\n",
      "Thu Dec 12 09:47:34 2024 69/630   max_epochs 1000\n",
      "Thu Dec 12 09:47:34 2024 69/630     inner fold 0\n",
      "Thu Dec 12 09:47:59 2024 70/630     inner fold 1\n",
      "Thu Dec 12 09:48:29 2024 71/630     inner fold 2\n",
      "Thu Dec 12 09:48:59 2024 72/630     inner fold 3\n",
      "Thu Dec 12 09:49:23 2024 73/630     inner fold 4 f1_tuned: 0.713\n",
      "Thu Dec 12 09:49:44 2024 74/630   batch size 1024\n",
      "Thu Dec 12 09:49:44 2024 74/630   max_epochs 500\n",
      "Thu Dec 12 09:49:44 2024 74/630     inner fold 0\n",
      "Thu Dec 12 09:50:59 2024 75/630     inner fold 1\n",
      "Thu Dec 12 09:52:07 2024 76/630     inner fold 2\n",
      "Thu Dec 12 09:53:21 2024 77/630     inner fold 3\n",
      "Thu Dec 12 09:54:35 2024 78/630     inner fold 4 f1_tuned: 0.715\n",
      "Thu Dec 12 09:55:09 2024 79/630   batch size 1024\n",
      "Thu Dec 12 09:55:09 2024 79/630   max_epochs 1000\n",
      "Thu Dec 12 09:55:09 2024 79/630     inner fold 0\n",
      "Thu Dec 12 09:55:43 2024 80/630     inner fold 1\n",
      "Thu Dec 12 09:56:23 2024 81/630     inner fold 2\n",
      "Thu Dec 12 09:58:43 2024 82/630     inner fold 3\n",
      "Thu Dec 12 09:59:17 2024 83/630     inner fold 4 f1_tuned: 0.714\n",
      "Thu Dec 12 09:59:49 2024 84/630   outer fold 3 with tuned HP f1_tuned: 0.689\n",
      "Thu Dec 12 10:00:31 2024 85/630 outer fold 4\n",
      "Thu Dec 12 10:00:31 2024 85/630   batch size 512\n",
      "Thu Dec 12 10:00:31 2024 85/630   max_epochs 500\n",
      "Thu Dec 12 10:00:31 2024 85/630     inner fold 0\n",
      "Thu Dec 12 10:01:33 2024 86/630     inner fold 1\n",
      "Thu Dec 12 10:01:56 2024 87/630     inner fold 2\n",
      "Thu Dec 12 10:02:45 2024 88/630     inner fold 3\n",
      "Thu Dec 12 10:03:48 2024 89/630     inner fold 4 f1_tuned: 0.708\n",
      "Thu Dec 12 10:04:51 2024 90/630   batch size 512\n",
      "Thu Dec 12 10:04:51 2024 90/630   max_epochs 1000\n",
      "Thu Dec 12 10:04:51 2024 90/630     inner fold 0\n",
      "Thu Dec 12 10:06:28 2024 91/630     inner fold 1\n",
      "Thu Dec 12 10:06:47 2024 92/630     inner fold 2\n",
      "Thu Dec 12 10:08:49 2024 93/630     inner fold 3\n",
      "Thu Dec 12 10:10:50 2024 94/630     inner fold 4 f1_tuned: 0.712\n",
      "Thu Dec 12 10:12:38 2024 95/630   batch size 1024\n",
      "Thu Dec 12 10:12:38 2024 95/630   max_epochs 500\n",
      "Thu Dec 12 10:12:38 2024 95/630     inner fold 0\n",
      "Thu Dec 12 10:13:49 2024 96/630     inner fold 1\n",
      "Thu Dec 12 10:14:27 2024 97/630     inner fold 2\n",
      "Thu Dec 12 10:15:06 2024 98/630     inner fold 3\n",
      "Thu Dec 12 10:16:17 2024 99/630     inner fold 4 f1_tuned: 0.707\n",
      "Thu Dec 12 10:16:57 2024 100/630   batch size 1024\n",
      "Thu Dec 12 10:16:57 2024 100/630   max_epochs 1000\n",
      "Thu Dec 12 10:16:57 2024 100/630     inner fold 0\n",
      "Thu Dec 12 10:17:32 2024 101/630     inner fold 1\n",
      "Thu Dec 12 10:18:01 2024 102/630     inner fold 2\n",
      "Thu Dec 12 10:18:44 2024 103/630     inner fold 3\n",
      "Thu Dec 12 10:19:53 2024 104/630     inner fold 4 f1_tuned: 0.710\n",
      "Thu Dec 12 10:22:16 2024 105/630   outer fold 4 with tuned HP f1_tuned: 0.719\n",
      "feature_selection: C\n",
      "relevant areas: ['area_sentinel_id_7', 'area_sentinel_id_9', 'area_sentinel_id_10']\n",
      "shape of feature matrix: (5335, 60)\n",
      "Thu Dec 12 10:24:27 2024 106/630 outer fold 0\n",
      "Thu Dec 12 10:24:27 2024 106/630   batch size 512\n",
      "Thu Dec 12 10:24:27 2024 106/630   max_epochs 500\n",
      "Thu Dec 12 10:24:27 2024 106/630     inner fold 0\n",
      "Thu Dec 12 10:25:18 2024 107/630     inner fold 1\n",
      "Thu Dec 12 10:26:15 2024 108/630     inner fold 2\n",
      "Thu Dec 12 10:26:37 2024 109/630     inner fold 3\n",
      "Thu Dec 12 10:27:33 2024 110/630     inner fold 4 f1_tuned: 0.759\n",
      "Thu Dec 12 10:28:29 2024 111/630   batch size 512\n",
      "Thu Dec 12 10:28:29 2024 111/630   max_epochs 1000\n",
      "Thu Dec 12 10:28:29 2024 111/630     inner fold 0\n",
      "Thu Dec 12 10:29:20 2024 112/630     inner fold 1\n",
      "Thu Dec 12 10:30:26 2024 113/630     inner fold 2\n",
      "Thu Dec 12 10:31:22 2024 114/630     inner fold 3\n",
      "Thu Dec 12 10:32:24 2024 115/630     inner fold 4 f1_tuned: 0.757\n",
      "Thu Dec 12 10:33:58 2024 116/630   batch size 1024\n",
      "Thu Dec 12 10:33:58 2024 116/630   max_epochs 500\n",
      "Thu Dec 12 10:33:58 2024 116/630     inner fold 0\n",
      "Thu Dec 12 10:34:57 2024 117/630     inner fold 1\n",
      "Thu Dec 12 10:35:56 2024 118/630     inner fold 2\n",
      "Thu Dec 12 10:36:55 2024 119/630     inner fold 3\n",
      "Thu Dec 12 10:37:54 2024 120/630     inner fold 4 f1_tuned: 0.757\n",
      "Thu Dec 12 10:38:52 2024 121/630   batch size 1024\n",
      "Thu Dec 12 10:38:52 2024 121/630   max_epochs 1000\n",
      "Thu Dec 12 10:38:52 2024 121/630     inner fold 0\n",
      "Thu Dec 12 10:40:19 2024 122/630     inner fold 1\n",
      "Thu Dec 12 10:41:52 2024 123/630     inner fold 2\n",
      "Thu Dec 12 10:43:03 2024 124/630     inner fold 3\n",
      "Thu Dec 12 10:44:48 2024 125/630     inner fold 4 f1_tuned: 0.762\n",
      "Thu Dec 12 10:46:03 2024 126/630   outer fold 0 with tuned HP f1_tuned: 0.746\n",
      "Thu Dec 12 10:47:30 2024 127/630 outer fold 1\n",
      "Thu Dec 12 10:47:30 2024 127/630   batch size 512\n",
      "Thu Dec 12 10:47:30 2024 127/630   max_epochs 500\n",
      "Thu Dec 12 10:47:30 2024 127/630     inner fold 0\n",
      "Thu Dec 12 10:48:41 2024 128/630     inner fold 1\n",
      "Thu Dec 12 10:49:38 2024 129/630     inner fold 2\n",
      "Thu Dec 12 10:50:01 2024 130/630     inner fold 3\n",
      "Thu Dec 12 10:51:04 2024 131/630     inner fold 4 f1_tuned: 0.744\n",
      "Thu Dec 12 10:52:06 2024 132/630   batch size 512\n",
      "Thu Dec 12 10:52:06 2024 132/630   max_epochs 1000\n",
      "Thu Dec 12 10:52:06 2024 132/630     inner fold 0\n",
      "Thu Dec 12 10:54:06 2024 133/630     inner fold 1\n",
      "Thu Dec 12 10:55:13 2024 134/630     inner fold 2\n",
      "Thu Dec 12 10:55:32 2024 135/630     inner fold 3\n",
      "Thu Dec 12 10:56:57 2024 136/630     inner fold 4 f1_tuned: 0.745\n",
      "Thu Dec 12 10:58:04 2024 137/630   batch size 1024\n",
      "Thu Dec 12 10:58:04 2024 137/630   max_epochs 500\n",
      "Thu Dec 12 10:58:04 2024 137/630     inner fold 0\n",
      "Thu Dec 12 10:59:08 2024 138/630     inner fold 1\n",
      "Thu Dec 12 11:00:12 2024 139/630     inner fold 2\n",
      "Thu Dec 12 11:00:42 2024 140/630     inner fold 3\n",
      "Thu Dec 12 11:01:45 2024 141/630     inner fold 4 f1_tuned: 0.742\n",
      "Thu Dec 12 11:02:48 2024 142/630   batch size 1024\n",
      "Thu Dec 12 11:02:48 2024 142/630   max_epochs 1000\n",
      "Thu Dec 12 11:02:48 2024 142/630     inner fold 0\n",
      "Thu Dec 12 11:04:19 2024 143/630     inner fold 1\n",
      "Thu Dec 12 11:05:33 2024 144/630     inner fold 2\n",
      "Thu Dec 12 11:06:00 2024 145/630     inner fold 3\n",
      "Thu Dec 12 11:07:59 2024 146/630     inner fold 4 f1_tuned: 0.745\n",
      "Thu Dec 12 11:09:49 2024 147/630   outer fold 1 with tuned HP f1_tuned: 0.765\n",
      "Thu Dec 12 11:11:57 2024 148/630 outer fold 2\n",
      "Thu Dec 12 11:11:57 2024 148/630   batch size 512\n",
      "Thu Dec 12 11:11:57 2024 148/630   max_epochs 500\n",
      "Thu Dec 12 11:11:57 2024 148/630     inner fold 0\n",
      "Thu Dec 12 11:12:23 2024 149/630     inner fold 1\n",
      "Thu Dec 12 11:13:22 2024 150/630     inner fold 2\n",
      "Thu Dec 12 11:14:15 2024 151/630     inner fold 3\n",
      "Thu Dec 12 11:15:06 2024 152/630     inner fold 4 f1_tuned: 0.752\n",
      "Thu Dec 12 11:16:04 2024 153/630   batch size 512\n",
      "Thu Dec 12 11:16:04 2024 153/630   max_epochs 1000\n",
      "Thu Dec 12 11:16:04 2024 153/630     inner fold 0\n",
      "Thu Dec 12 11:16:22 2024 154/630     inner fold 1\n",
      "Thu Dec 12 11:17:28 2024 155/630     inner fold 2\n",
      "Thu Dec 12 11:18:16 2024 156/630     inner fold 3\n",
      "Thu Dec 12 11:19:15 2024 157/630     inner fold 4 f1_tuned: 0.752\n",
      "Thu Dec 12 11:20:05 2024 158/630   batch size 1024\n",
      "Thu Dec 12 11:20:05 2024 158/630   max_epochs 500\n",
      "Thu Dec 12 11:20:05 2024 158/630     inner fold 0\n",
      "Thu Dec 12 11:20:40 2024 159/630     inner fold 1\n",
      "Thu Dec 12 11:21:40 2024 160/630     inner fold 2\n",
      "Thu Dec 12 11:22:39 2024 161/630     inner fold 3\n",
      "Thu Dec 12 11:23:37 2024 162/630     inner fold 4 f1_tuned: 0.751\n",
      "Thu Dec 12 11:24:37 2024 163/630   batch size 1024\n",
      "Thu Dec 12 11:24:37 2024 163/630   max_epochs 1000\n",
      "Thu Dec 12 11:24:37 2024 163/630     inner fold 0\n",
      "Thu Dec 12 11:25:04 2024 164/630     inner fold 1\n",
      "Thu Dec 12 11:26:08 2024 165/630     inner fold 2\n",
      "Thu Dec 12 11:27:09 2024 166/630     inner fold 3\n",
      "Thu Dec 12 11:28:24 2024 167/630     inner fold 4 f1_tuned: 0.751\n",
      "Thu Dec 12 11:29:55 2024 168/630   outer fold 2 with tuned HP f1_tuned: 0.750\n",
      "Thu Dec 12 11:30:54 2024 169/630 outer fold 3\n",
      "Thu Dec 12 11:30:54 2024 169/630   batch size 512\n",
      "Thu Dec 12 11:30:54 2024 169/630   max_epochs 500\n",
      "Thu Dec 12 11:30:54 2024 169/630     inner fold 0\n",
      "Thu Dec 12 11:31:11 2024 170/630     inner fold 1\n",
      "Thu Dec 12 11:31:28 2024 171/630     inner fold 2\n",
      "Thu Dec 12 11:31:49 2024 172/630     inner fold 3\n",
      "Thu Dec 12 11:32:45 2024 173/630     inner fold 4 f1_tuned: 0.745\n",
      "Thu Dec 12 11:33:09 2024 174/630   batch size 512\n",
      "Thu Dec 12 11:33:09 2024 174/630   max_epochs 1000\n",
      "Thu Dec 12 11:33:09 2024 174/630     inner fold 0\n",
      "Thu Dec 12 11:34:36 2024 175/630     inner fold 1\n",
      "Thu Dec 12 11:35:46 2024 176/630     inner fold 2\n",
      "Thu Dec 12 11:36:04 2024 177/630     inner fold 3\n",
      "Thu Dec 12 11:36:58 2024 178/630     inner fold 4 f1_tuned: 0.750\n",
      "Thu Dec 12 11:37:21 2024 179/630   batch size 1024\n",
      "Thu Dec 12 11:37:21 2024 179/630   max_epochs 500\n",
      "Thu Dec 12 11:37:21 2024 179/630     inner fold 0\n",
      "Thu Dec 12 11:37:52 2024 180/630     inner fold 1\n",
      "Thu Dec 12 11:38:14 2024 181/630     inner fold 2\n",
      "Thu Dec 12 11:38:40 2024 182/630     inner fold 3\n",
      "Thu Dec 12 11:39:38 2024 183/630     inner fold 4 f1_tuned: 0.749\n",
      "Thu Dec 12 11:40:35 2024 184/630   batch size 1024\n",
      "Thu Dec 12 11:40:35 2024 184/630   max_epochs 1000\n",
      "Thu Dec 12 11:40:35 2024 184/630     inner fold 0\n",
      "Thu Dec 12 11:40:59 2024 185/630     inner fold 1\n",
      "Thu Dec 12 11:42:46 2024 186/630     inner fold 2\n",
      "Thu Dec 12 11:43:16 2024 187/630     inner fold 3\n",
      "Thu Dec 12 11:44:38 2024 188/630     inner fold 4 f1_tuned: 0.754\n",
      "Thu Dec 12 11:45:52 2024 189/630   outer fold 3 with tuned HP f1_tuned: 0.756\n",
      "Thu Dec 12 11:47:39 2024 190/630 outer fold 4\n",
      "Thu Dec 12 11:47:39 2024 190/630   batch size 512\n",
      "Thu Dec 12 11:47:39 2024 190/630   max_epochs 500\n",
      "Thu Dec 12 11:47:39 2024 190/630     inner fold 0\n",
      "Thu Dec 12 11:48:30 2024 191/630     inner fold 1\n",
      "Thu Dec 12 11:49:10 2024 192/630     inner fold 2\n",
      "Thu Dec 12 11:50:05 2024 193/630     inner fold 3\n",
      "Thu Dec 12 11:50:59 2024 194/630     inner fold 4 f1_tuned: 0.751\n",
      "Thu Dec 12 11:51:54 2024 195/630   batch size 512\n",
      "Thu Dec 12 11:51:54 2024 195/630   max_epochs 1000\n",
      "Thu Dec 12 11:51:54 2024 195/630     inner fold 0\n",
      "Thu Dec 12 11:53:01 2024 196/630     inner fold 1\n",
      "Thu Dec 12 11:53:42 2024 197/630     inner fold 2\n",
      "Thu Dec 12 11:54:51 2024 198/630     inner fold 3\n",
      "Thu Dec 12 11:56:37 2024 199/630     inner fold 4 f1_tuned: 0.755\n",
      "Thu Dec 12 11:58:11 2024 200/630   batch size 1024\n",
      "Thu Dec 12 11:58:11 2024 200/630   max_epochs 500\n",
      "Thu Dec 12 11:58:11 2024 200/630     inner fold 0\n",
      "Thu Dec 12 11:59:07 2024 201/630     inner fold 1\n",
      "Thu Dec 12 12:00:03 2024 202/630     inner fold 2\n",
      "Thu Dec 12 12:00:59 2024 203/630     inner fold 3\n",
      "Thu Dec 12 12:01:54 2024 204/630     inner fold 4 f1_tuned: 0.750\n",
      "Thu Dec 12 12:03:12 2024 205/630   batch size 1024\n",
      "Thu Dec 12 12:03:12 2024 205/630   max_epochs 1000\n",
      "Thu Dec 12 12:03:12 2024 205/630     inner fold 0\n",
      "Thu Dec 12 12:04:39 2024 206/630     inner fold 1\n",
      "Thu Dec 12 12:05:46 2024 207/630     inner fold 2\n",
      "Thu Dec 12 12:07:27 2024 208/630     inner fold 3\n",
      "Thu Dec 12 12:09:37 2024 209/630     inner fold 4 f1_tuned: 0.755\n",
      "Thu Dec 12 12:11:48 2024 210/630   outer fold 4 with tuned HP f1_tuned: 0.781\n",
      "\n",
      " ************************************************** \n",
      "\n",
      " METOLACHLOR-CA \n",
      "\n",
      "feature_selection: A\n",
      "relevant areas: ['area_sentinel_id_7', 'area_sentinel_id_9', 'area_sentinel_id_10']\n",
      "shape of feature matrix: (8974, 17)\n",
      "Thu Dec 12 12:13:40 2024 211/630 outer fold 0\n",
      "Thu Dec 12 12:13:40 2024 211/630   batch size 512\n",
      "Thu Dec 12 12:13:40 2024 211/630   max_epochs 500\n",
      "Thu Dec 12 12:13:40 2024 211/630     inner fold 0\n",
      "Thu Dec 12 12:13:59 2024 212/630     inner fold 1\n",
      "Thu Dec 12 12:14:25 2024 213/630     inner fold 2\n",
      "Thu Dec 12 12:14:44 2024 214/630     inner fold 3\n",
      "Thu Dec 12 12:15:04 2024 215/630     inner fold 4 f1_tuned: 0.698\n",
      "Thu Dec 12 12:16:13 2024 216/630   batch size 512\n",
      "Thu Dec 12 12:16:13 2024 216/630   max_epochs 1000\n",
      "Thu Dec 12 12:16:13 2024 216/630     inner fold 0\n",
      "Thu Dec 12 12:16:32 2024 217/630     inner fold 1\n",
      "Thu Dec 12 12:16:59 2024 218/630     inner fold 2\n",
      "Thu Dec 12 12:17:20 2024 219/630     inner fold 3\n",
      "Thu Dec 12 12:17:39 2024 220/630     inner fold 4 f1_tuned: 0.698\n",
      "Thu Dec 12 12:18:08 2024 221/630   batch size 1024\n",
      "Thu Dec 12 12:18:08 2024 221/630   max_epochs 500\n",
      "Thu Dec 12 12:18:08 2024 221/630     inner fold 0\n",
      "Thu Dec 12 12:18:47 2024 222/630     inner fold 1\n",
      "Thu Dec 12 12:19:28 2024 223/630     inner fold 2\n",
      "Thu Dec 12 12:19:59 2024 224/630     inner fold 3\n",
      "Thu Dec 12 12:20:37 2024 225/630     inner fold 4 f1_tuned: 0.696\n",
      "Thu Dec 12 12:21:28 2024 226/630   batch size 1024\n",
      "Thu Dec 12 12:21:28 2024 226/630   max_epochs 1000\n",
      "Thu Dec 12 12:21:28 2024 226/630     inner fold 0\n",
      "Thu Dec 12 12:21:56 2024 227/630     inner fold 1\n",
      "Thu Dec 12 12:22:43 2024 228/630     inner fold 2\n",
      "Thu Dec 12 12:23:09 2024 229/630     inner fold 3\n",
      "Thu Dec 12 12:23:38 2024 230/630     inner fold 4 f1_tuned: 0.700\n",
      "Thu Dec 12 12:26:04 2024 231/630   outer fold 0 with tuned HP f1_tuned: 0.686\n",
      "Thu Dec 12 12:26:59 2024 232/630 outer fold 1\n",
      "Thu Dec 12 12:26:59 2024 232/630   batch size 512\n",
      "Thu Dec 12 12:26:59 2024 232/630   max_epochs 500\n",
      "Thu Dec 12 12:26:59 2024 232/630     inner fold 0\n",
      "Thu Dec 12 12:27:24 2024 233/630     inner fold 1\n",
      "Thu Dec 12 12:27:44 2024 234/630     inner fold 2\n",
      "Thu Dec 12 12:28:04 2024 235/630     inner fold 3\n",
      "Thu Dec 12 12:28:26 2024 236/630     inner fold 4 f1_tuned: 0.697\n",
      "Thu Dec 12 12:28:44 2024 237/630   batch size 512\n",
      "Thu Dec 12 12:28:44 2024 237/630   max_epochs 1000\n",
      "Thu Dec 12 12:28:44 2024 237/630     inner fold 0\n",
      "Thu Dec 12 12:29:12 2024 238/630     inner fold 1\n",
      "Thu Dec 12 12:29:35 2024 239/630     inner fold 2\n",
      "Thu Dec 12 12:29:55 2024 240/630     inner fold 3\n",
      "Thu Dec 12 12:30:24 2024 241/630     inner fold 4 f1_tuned: 0.696\n",
      "Thu Dec 12 12:30:44 2024 242/630   batch size 1024\n",
      "Thu Dec 12 12:30:44 2024 242/630   max_epochs 500\n",
      "Thu Dec 12 12:30:44 2024 242/630     inner fold 0\n",
      "Thu Dec 12 12:31:14 2024 243/630     inner fold 1\n",
      "Thu Dec 12 12:31:42 2024 244/630     inner fold 2\n",
      "Thu Dec 12 12:32:07 2024 245/630     inner fold 3\n",
      "Thu Dec 12 12:32:48 2024 246/630     inner fold 4 f1_tuned: 0.697\n",
      "Thu Dec 12 12:33:21 2024 247/630   batch size 1024\n",
      "Thu Dec 12 12:33:21 2024 247/630   max_epochs 1000\n",
      "Thu Dec 12 12:33:21 2024 247/630     inner fold 0\n",
      "Thu Dec 12 12:33:53 2024 248/630     inner fold 1\n",
      "Thu Dec 12 12:34:21 2024 249/630     inner fold 2\n",
      "Thu Dec 12 12:34:43 2024 250/630     inner fold 3\n",
      "Thu Dec 12 12:35:24 2024 251/630     inner fold 4 f1_tuned: 0.697\n",
      "Thu Dec 12 12:35:54 2024 252/630   outer fold 1 with tuned HP f1_tuned: 0.686\n",
      "Thu Dec 12 12:36:19 2024 253/630 outer fold 2\n",
      "Thu Dec 12 12:36:19 2024 253/630   batch size 512\n",
      "Thu Dec 12 12:36:19 2024 253/630   max_epochs 500\n",
      "Thu Dec 12 12:36:19 2024 253/630     inner fold 0\n",
      "Thu Dec 12 12:36:42 2024 254/630     inner fold 1\n",
      "Thu Dec 12 12:37:04 2024 255/630     inner fold 2\n",
      "Thu Dec 12 12:37:29 2024 256/630     inner fold 3\n",
      "Thu Dec 12 12:38:32 2024 257/630     inner fold 4 f1_tuned: 0.700\n",
      "Thu Dec 12 12:38:54 2024 258/630   batch size 512\n",
      "Thu Dec 12 12:38:54 2024 258/630   max_epochs 1000\n",
      "Thu Dec 12 12:38:54 2024 258/630     inner fold 0\n",
      "Thu Dec 12 12:40:05 2024 259/630     inner fold 1\n",
      "Thu Dec 12 12:40:28 2024 260/630     inner fold 2\n",
      "Thu Dec 12 12:42:31 2024 261/630     inner fold 3\n",
      "Thu Dec 12 12:44:20 2024 262/630     inner fold 4 f1_tuned: 0.701\n",
      "Thu Dec 12 12:44:41 2024 263/630   batch size 1024\n",
      "Thu Dec 12 12:44:41 2024 263/630   max_epochs 500\n",
      "Thu Dec 12 12:44:41 2024 263/630     inner fold 0\n",
      "Thu Dec 12 12:45:10 2024 264/630     inner fold 1\n",
      "Thu Dec 12 12:45:49 2024 265/630     inner fold 2\n",
      "Thu Dec 12 12:46:27 2024 266/630     inner fold 3\n",
      "Thu Dec 12 12:47:21 2024 267/630     inner fold 4 f1_tuned: 0.699\n",
      "Thu Dec 12 12:47:54 2024 268/630   batch size 1024\n",
      "Thu Dec 12 12:47:54 2024 268/630   max_epochs 1000\n",
      "Thu Dec 12 12:47:54 2024 268/630     inner fold 0\n",
      "Thu Dec 12 12:48:58 2024 269/630     inner fold 1\n",
      "Thu Dec 12 12:49:31 2024 270/630     inner fold 2\n",
      "Thu Dec 12 12:50:08 2024 271/630     inner fold 3\n",
      "Thu Dec 12 12:50:48 2024 272/630     inner fold 4 f1_tuned: 0.699\n",
      "Thu Dec 12 12:51:17 2024 273/630   outer fold 2 with tuned HP f1_tuned: 0.684\n",
      "Thu Dec 12 12:51:34 2024 274/630 outer fold 3\n",
      "Thu Dec 12 12:51:34 2024 274/630   batch size 512\n",
      "Thu Dec 12 12:51:34 2024 274/630   max_epochs 500\n",
      "Thu Dec 12 12:51:34 2024 274/630     inner fold 0\n",
      "Thu Dec 12 12:51:53 2024 275/630     inner fold 1\n",
      "Thu Dec 12 12:52:17 2024 276/630     inner fold 2\n",
      "Thu Dec 12 12:52:41 2024 277/630     inner fold 3\n",
      "Thu Dec 12 12:53:44 2024 278/630     inner fold 4 f1_tuned: 0.691\n",
      "Thu Dec 12 12:54:05 2024 279/630   batch size 512\n",
      "Thu Dec 12 12:54:05 2024 279/630   max_epochs 1000\n",
      "Thu Dec 12 12:54:05 2024 279/630     inner fold 0\n",
      "Thu Dec 12 12:54:26 2024 280/630     inner fold 1\n",
      "Thu Dec 12 12:54:49 2024 281/630     inner fold 2\n",
      "Thu Dec 12 12:55:08 2024 282/630     inner fold 3\n",
      "Thu Dec 12 12:57:05 2024 283/630     inner fold 4 f1_tuned: 0.690\n",
      "Thu Dec 12 12:57:27 2024 284/630   batch size 1024\n",
      "Thu Dec 12 12:57:27 2024 284/630   max_epochs 500\n",
      "Thu Dec 12 12:57:27 2024 284/630     inner fold 0\n",
      "Thu Dec 12 12:58:08 2024 285/630     inner fold 1\n",
      "Thu Dec 12 12:58:36 2024 286/630     inner fold 2\n",
      "Thu Dec 12 12:59:11 2024 287/630     inner fold 3\n",
      "Thu Dec 12 13:00:21 2024 288/630     inner fold 4 f1_tuned: 0.690\n",
      "Thu Dec 12 13:00:54 2024 289/630   batch size 1024\n",
      "Thu Dec 12 13:00:54 2024 289/630   max_epochs 1000\n",
      "Thu Dec 12 13:00:54 2024 289/630     inner fold 0\n",
      "Thu Dec 12 13:01:23 2024 290/630     inner fold 1\n",
      "Thu Dec 12 13:02:07 2024 291/630     inner fold 2\n",
      "Thu Dec 12 13:02:36 2024 292/630     inner fold 3\n",
      "Thu Dec 12 13:03:48 2024 293/630     inner fold 4 f1_tuned: 0.690\n",
      "Thu Dec 12 13:04:14 2024 294/630   outer fold 3 with tuned HP f1_tuned: 0.721\n",
      "Thu Dec 12 13:05:51 2024 295/630 outer fold 4\n",
      "Thu Dec 12 13:05:51 2024 295/630   batch size 512\n",
      "Thu Dec 12 13:05:51 2024 295/630   max_epochs 500\n",
      "Thu Dec 12 13:05:51 2024 295/630     inner fold 0\n",
      "Thu Dec 12 13:06:18 2024 296/630     inner fold 1\n",
      "Thu Dec 12 13:06:48 2024 297/630     inner fold 2\n",
      "Thu Dec 12 13:08:01 2024 298/630     inner fold 3\n",
      "Thu Dec 12 13:09:13 2024 299/630     inner fold 4 f1_tuned: 0.695\n",
      "Thu Dec 12 13:09:36 2024 300/630   batch size 512\n",
      "Thu Dec 12 13:09:36 2024 300/630   max_epochs 1000\n",
      "Thu Dec 12 13:09:36 2024 300/630     inner fold 0\n",
      "Thu Dec 12 13:09:57 2024 301/630     inner fold 1\n",
      "Thu Dec 12 13:10:23 2024 302/630     inner fold 2\n",
      "Thu Dec 12 13:11:33 2024 303/630     inner fold 3\n",
      "Thu Dec 12 13:13:51 2024 304/630     inner fold 4 f1_tuned: 0.696\n",
      "Thu Dec 12 13:14:18 2024 305/630   batch size 1024\n",
      "Thu Dec 12 13:14:18 2024 305/630   max_epochs 500\n",
      "Thu Dec 12 13:14:18 2024 305/630     inner fold 0\n",
      "Thu Dec 12 13:14:51 2024 306/630     inner fold 1\n",
      "Thu Dec 12 13:15:39 2024 307/630     inner fold 2\n",
      "Thu Dec 12 13:16:39 2024 308/630     inner fold 3\n",
      "Thu Dec 12 13:18:05 2024 309/630     inner fold 4 f1_tuned: 0.694\n",
      "Thu Dec 12 13:18:40 2024 310/630   batch size 1024\n",
      "Thu Dec 12 13:18:40 2024 310/630   max_epochs 1000\n",
      "Thu Dec 12 13:18:40 2024 310/630     inner fold 0\n",
      "Thu Dec 12 13:19:28 2024 311/630     inner fold 1\n",
      "Thu Dec 12 13:20:04 2024 312/630     inner fold 2\n",
      "Thu Dec 12 13:21:30 2024 313/630     inner fold 3\n",
      "Thu Dec 12 13:22:09 2024 314/630     inner fold 4 f1_tuned: 0.695\n",
      "Thu Dec 12 13:22:51 2024 315/630   outer fold 4 with tuned HP f1_tuned: 0.705\n",
      "feature_selection: C\n",
      "relevant areas: ['area_sentinel_id_7', 'area_sentinel_id_9', 'area_sentinel_id_10']\n",
      "shape of feature matrix: (5289, 60)\n",
      "Thu Dec 12 13:24:13 2024 316/630 outer fold 0\n",
      "Thu Dec 12 13:24:13 2024 316/630   batch size 512\n",
      "Thu Dec 12 13:24:13 2024 316/630   max_epochs 500\n",
      "Thu Dec 12 13:24:13 2024 316/630     inner fold 0\n",
      "Thu Dec 12 13:25:12 2024 317/630     inner fold 1\n",
      "Thu Dec 12 13:26:09 2024 318/630     inner fold 2\n",
      "Thu Dec 12 13:26:47 2024 319/630     inner fold 3\n",
      "Thu Dec 12 13:27:38 2024 320/630     inner fold 4 f1_tuned: 0.739\n",
      "Thu Dec 12 13:28:19 2024 321/630   batch size 512\n",
      "Thu Dec 12 13:28:19 2024 321/630   max_epochs 1000\n",
      "Thu Dec 12 13:28:19 2024 321/630     inner fold 0\n",
      "Thu Dec 12 13:29:30 2024 322/630     inner fold 1\n",
      "Thu Dec 12 13:30:17 2024 323/630     inner fold 2\n",
      "Thu Dec 12 13:30:55 2024 324/630     inner fold 3\n",
      "Thu Dec 12 13:31:45 2024 325/630     inner fold 4 f1_tuned: 0.738\n",
      "Thu Dec 12 13:32:43 2024 326/630   batch size 1024\n",
      "Thu Dec 12 13:32:43 2024 326/630   max_epochs 500\n",
      "Thu Dec 12 13:32:43 2024 326/630     inner fold 0\n",
      "Thu Dec 12 13:33:44 2024 327/630     inner fold 1\n",
      "Thu Dec 12 13:34:45 2024 328/630     inner fold 2\n",
      "Thu Dec 12 13:35:46 2024 329/630     inner fold 3\n",
      "Thu Dec 12 13:36:32 2024 330/630     inner fold 4 f1_tuned: 0.739\n",
      "Thu Dec 12 13:37:33 2024 331/630   batch size 1024\n",
      "Thu Dec 12 13:37:33 2024 331/630   max_epochs 1000\n",
      "Thu Dec 12 13:37:33 2024 331/630     inner fold 0\n",
      "Thu Dec 12 13:39:25 2024 332/630     inner fold 1\n",
      "Thu Dec 12 13:40:31 2024 333/630     inner fold 2\n",
      "Thu Dec 12 13:41:21 2024 334/630     inner fold 3\n",
      "Thu Dec 12 13:42:37 2024 335/630     inner fold 4 f1_tuned: 0.739\n",
      "Thu Dec 12 13:43:49 2024 336/630   outer fold 0 with tuned HP f1_tuned: 0.747\n",
      "Thu Dec 12 13:44:47 2024 337/630 outer fold 1\n",
      "Thu Dec 12 13:44:47 2024 337/630   batch size 512\n",
      "Thu Dec 12 13:44:47 2024 337/630   max_epochs 500\n",
      "Thu Dec 12 13:44:47 2024 337/630     inner fold 0\n",
      "Thu Dec 12 13:45:23 2024 338/630     inner fold 1\n",
      "Thu Dec 12 13:46:21 2024 339/630     inner fold 2\n",
      "Thu Dec 12 13:47:03 2024 340/630     inner fold 3\n",
      "Thu Dec 12 13:48:01 2024 341/630     inner fold 4 f1_tuned: 0.735\n",
      "Thu Dec 12 13:48:45 2024 342/630   batch size 512\n",
      "Thu Dec 12 13:48:45 2024 342/630   max_epochs 1000\n",
      "Thu Dec 12 13:48:45 2024 342/630     inner fold 0\n",
      "Thu Dec 12 13:49:20 2024 343/630     inner fold 1\n",
      "Thu Dec 12 13:50:03 2024 344/630     inner fold 2\n",
      "Thu Dec 12 13:50:44 2024 345/630     inner fold 3\n",
      "Thu Dec 12 13:51:55 2024 346/630     inner fold 4 f1_tuned: 0.740\n",
      "Thu Dec 12 13:52:39 2024 347/630   batch size 1024\n",
      "Thu Dec 12 13:52:39 2024 347/630   max_epochs 500\n",
      "Thu Dec 12 13:52:39 2024 347/630     inner fold 0\n",
      "Thu Dec 12 13:53:28 2024 348/630     inner fold 1\n",
      "Thu Dec 12 13:54:29 2024 349/630     inner fold 2\n",
      "Thu Dec 12 13:55:30 2024 350/630     inner fold 3\n",
      "Thu Dec 12 13:56:31 2024 351/630     inner fold 4 f1_tuned: 0.737\n",
      "Thu Dec 12 13:57:23 2024 352/630   batch size 1024\n",
      "Thu Dec 12 13:57:23 2024 352/630   max_epochs 1000\n",
      "Thu Dec 12 13:57:23 2024 352/630     inner fold 0\n",
      "Thu Dec 12 13:58:17 2024 353/630     inner fold 1\n",
      "Thu Dec 12 13:59:22 2024 354/630     inner fold 2\n",
      "Thu Dec 12 14:00:36 2024 355/630     inner fold 3\n",
      "Thu Dec 12 14:02:28 2024 356/630     inner fold 4 f1_tuned: 0.738\n",
      "Thu Dec 12 14:03:22 2024 357/630   outer fold 1 with tuned HP f1_tuned: 0.741\n",
      "Thu Dec 12 14:04:20 2024 358/630 outer fold 2\n",
      "Thu Dec 12 14:04:20 2024 358/630   batch size 512\n",
      "Thu Dec 12 14:04:20 2024 358/630   max_epochs 500\n",
      "Thu Dec 12 14:04:20 2024 358/630     inner fold 0\n",
      "Thu Dec 12 14:05:16 2024 359/630     inner fold 1\n",
      "Thu Dec 12 14:06:13 2024 360/630     inner fold 2\n",
      "Thu Dec 12 14:07:10 2024 361/630     inner fold 3\n",
      "Thu Dec 12 14:07:33 2024 362/630     inner fold 4 f1_tuned: 0.743\n",
      "Thu Dec 12 14:08:30 2024 363/630   batch size 512\n",
      "Thu Dec 12 14:08:30 2024 363/630   max_epochs 1000\n",
      "Thu Dec 12 14:08:30 2024 363/630     inner fold 0\n",
      "Thu Dec 12 14:09:40 2024 364/630     inner fold 1\n",
      "Thu Dec 12 14:10:43 2024 365/630     inner fold 2\n",
      "Thu Dec 12 14:11:55 2024 366/630     inner fold 3\n",
      "Thu Dec 12 14:12:15 2024 367/630     inner fold 4 f1_tuned: 0.741\n",
      "Thu Dec 12 14:13:34 2024 368/630   batch size 1024\n",
      "Thu Dec 12 14:13:34 2024 368/630   max_epochs 500\n",
      "Thu Dec 12 14:13:34 2024 368/630     inner fold 0\n",
      "Thu Dec 12 14:14:34 2024 369/630     inner fold 1\n",
      "Thu Dec 12 14:15:34 2024 370/630     inner fold 2\n",
      "Thu Dec 12 14:16:33 2024 371/630     inner fold 3\n",
      "Thu Dec 12 14:17:05 2024 372/630     inner fold 4 f1_tuned: 0.743\n",
      "Thu Dec 12 14:18:04 2024 373/630   batch size 1024\n",
      "Thu Dec 12 14:18:04 2024 373/630   max_epochs 1000\n",
      "Thu Dec 12 14:18:04 2024 373/630     inner fold 0\n",
      "Thu Dec 12 14:19:41 2024 374/630     inner fold 1\n",
      "Thu Dec 12 14:21:14 2024 375/630     inner fold 2\n",
      "Thu Dec 12 14:22:48 2024 376/630     inner fold 3\n",
      "Thu Dec 12 14:23:17 2024 377/630     inner fold 4 f1_tuned: 0.740\n",
      "Thu Dec 12 14:25:04 2024 378/630   outer fold 2 with tuned HP f1_tuned: 0.734\n",
      "Thu Dec 12 14:25:53 2024 379/630 outer fold 3\n",
      "Thu Dec 12 14:25:53 2024 379/630   batch size 512\n",
      "Thu Dec 12 14:25:53 2024 379/630   max_epochs 500\n",
      "Thu Dec 12 14:25:53 2024 379/630     inner fold 0\n",
      "Thu Dec 12 14:26:50 2024 380/630     inner fold 1\n",
      "Thu Dec 12 14:27:47 2024 381/630     inner fold 2\n",
      "Thu Dec 12 14:28:22 2024 382/630     inner fold 3\n",
      "Thu Dec 12 14:29:05 2024 383/630     inner fold 4 f1_tuned: 0.729\n",
      "Thu Dec 12 14:29:29 2024 384/630   batch size 512\n",
      "Thu Dec 12 14:29:29 2024 384/630   max_epochs 1000\n",
      "Thu Dec 12 14:29:29 2024 384/630     inner fold 0\n",
      "Thu Dec 12 14:31:17 2024 385/630     inner fold 1\n",
      "Thu Dec 12 14:31:47 2024 386/630     inner fold 2\n",
      "Thu Dec 12 14:33:03 2024 387/630     inner fold 3\n",
      "Thu Dec 12 14:33:34 2024 388/630     inner fold 4 f1_tuned: 0.727\n",
      "Thu Dec 12 14:34:08 2024 389/630   batch size 1024\n",
      "Thu Dec 12 14:34:08 2024 389/630   max_epochs 500\n",
      "Thu Dec 12 14:34:08 2024 389/630     inner fold 0\n",
      "Thu Dec 12 14:35:05 2024 390/630     inner fold 1\n",
      "Thu Dec 12 14:36:03 2024 391/630     inner fold 2\n",
      "Thu Dec 12 14:37:01 2024 392/630     inner fold 3\n",
      "Thu Dec 12 14:37:49 2024 393/630     inner fold 4 f1_tuned: 0.729\n",
      "Thu Dec 12 14:38:48 2024 394/630   batch size 1024\n",
      "Thu Dec 12 14:38:48 2024 394/630   max_epochs 1000\n",
      "Thu Dec 12 14:38:48 2024 394/630     inner fold 0\n",
      "Thu Dec 12 14:40:27 2024 395/630     inner fold 1\n",
      "Thu Dec 12 14:42:14 2024 396/630     inner fold 2\n",
      "Thu Dec 12 14:43:19 2024 397/630     inner fold 3\n",
      "Thu Dec 12 14:44:12 2024 398/630     inner fold 4 f1_tuned: 0.730\n",
      "Thu Dec 12 14:46:18 2024 399/630   outer fold 3 with tuned HP f1_tuned: 0.770\n",
      "Thu Dec 12 14:47:43 2024 400/630 outer fold 4\n",
      "Thu Dec 12 14:47:43 2024 400/630   batch size 512\n",
      "Thu Dec 12 14:47:43 2024 400/630   max_epochs 500\n",
      "Thu Dec 12 14:47:43 2024 400/630     inner fold 0\n",
      "Thu Dec 12 14:48:50 2024 401/630     inner fold 1\n",
      "Thu Dec 12 14:49:57 2024 402/630     inner fold 2\n",
      "Thu Dec 12 14:51:00 2024 403/630     inner fold 3\n",
      "Thu Dec 12 14:51:29 2024 404/630     inner fold 4 f1_tuned: 0.747\n",
      "Thu Dec 12 14:52:35 2024 405/630   batch size 512\n",
      "Thu Dec 12 14:52:35 2024 405/630   max_epochs 1000\n",
      "Thu Dec 12 14:52:35 2024 405/630     inner fold 0\n",
      "Thu Dec 12 14:53:29 2024 406/630     inner fold 1\n",
      "Thu Dec 12 14:54:43 2024 407/630     inner fold 2\n",
      "Thu Dec 12 14:55:35 2024 408/630     inner fold 3\n",
      "Thu Dec 12 14:56:05 2024 409/630     inner fold 4 f1_tuned: 0.744\n",
      "Thu Dec 12 14:56:54 2024 410/630   batch size 1024\n",
      "Thu Dec 12 14:56:54 2024 410/630   max_epochs 500\n",
      "Thu Dec 12 14:56:54 2024 410/630     inner fold 0\n",
      "Thu Dec 12 14:58:04 2024 411/630     inner fold 1\n",
      "Thu Dec 12 14:59:14 2024 412/630     inner fold 2\n",
      "Thu Dec 12 15:00:24 2024 413/630     inner fold 3\n",
      "Thu Dec 12 15:01:06 2024 414/630     inner fold 4 f1_tuned: 0.747\n",
      "Thu Dec 12 15:02:16 2024 415/630   batch size 1024\n",
      "Thu Dec 12 15:02:16 2024 415/630   max_epochs 1000\n",
      "Thu Dec 12 15:02:16 2024 415/630     inner fold 0\n",
      "Thu Dec 12 15:03:50 2024 416/630     inner fold 1\n",
      "Thu Dec 12 15:05:23 2024 417/630     inner fold 2\n",
      "Thu Dec 12 15:06:28 2024 418/630     inner fold 3\n",
      "Thu Dec 12 15:07:14 2024 419/630     inner fold 4 f1_tuned: 0.750\n",
      "Thu Dec 12 15:08:42 2024 420/630   outer fold 4 with tuned HP f1_tuned: 0.730\n",
      "\n",
      " ************************************************** \n",
      "\n",
      " S-METOLACHLOR-METABOLIT NOA 413173 \n",
      "\n",
      "feature_selection: A\n",
      "relevant areas: ['area_sentinel_id_7', 'area_sentinel_id_9', 'area_sentinel_id_10']\n",
      "shape of feature matrix: (5793, 17)\n",
      "Thu Dec 12 15:10:15 2024 421/630 outer fold 0\n",
      "Thu Dec 12 15:10:15 2024 421/630   batch size 512\n",
      "Thu Dec 12 15:10:15 2024 421/630   max_epochs 500\n",
      "Thu Dec 12 15:10:15 2024 421/630     inner fold 0\n",
      "Thu Dec 12 15:11:14 2024 422/630     inner fold 1\n",
      "Thu Dec 12 15:12:13 2024 423/630     inner fold 2\n",
      "Thu Dec 12 15:12:51 2024 424/630     inner fold 3\n",
      "Thu Dec 12 15:13:50 2024 425/630     inner fold 4 f1_tuned: 0.667\n",
      "Thu Dec 12 15:14:50 2024 426/630   batch size 512\n",
      "Thu Dec 12 15:14:50 2024 426/630   max_epochs 1000\n",
      "Thu Dec 12 15:14:50 2024 426/630     inner fold 0\n",
      "Thu Dec 12 15:16:11 2024 427/630     inner fold 1\n",
      "Thu Dec 12 15:17:55 2024 428/630     inner fold 2\n",
      "Thu Dec 12 15:18:31 2024 429/630     inner fold 3\n",
      "Thu Dec 12 15:20:25 2024 430/630     inner fold 4 f1_tuned: 0.675\n",
      "Thu Dec 12 15:22:21 2024 431/630   batch size 1024\n",
      "Thu Dec 12 15:22:21 2024 431/630   max_epochs 500\n",
      "Thu Dec 12 15:22:21 2024 431/630     inner fold 0\n",
      "Thu Dec 12 15:23:27 2024 432/630     inner fold 1\n",
      "Thu Dec 12 15:24:32 2024 433/630     inner fold 2\n",
      "Thu Dec 12 15:25:37 2024 434/630     inner fold 3\n",
      "Thu Dec 12 15:26:40 2024 435/630     inner fold 4 f1_tuned: 0.664\n",
      "Thu Dec 12 15:27:45 2024 436/630   batch size 1024\n",
      "Thu Dec 12 15:27:45 2024 436/630   max_epochs 1000\n",
      "Thu Dec 12 15:27:45 2024 436/630     inner fold 0\n",
      "Thu Dec 12 15:29:24 2024 437/630     inner fold 1\n",
      "Thu Dec 12 15:31:19 2024 438/630     inner fold 2\n",
      "Thu Dec 12 15:33:23 2024 439/630     inner fold 3\n",
      "Thu Dec 12 15:34:26 2024 440/630     inner fold 4 f1_tuned: 0.671\n",
      "Thu Dec 12 15:36:30 2024 441/630   outer fold 0 with tuned HP f1_tuned: 0.669\n",
      "Thu Dec 12 15:36:50 2024 442/630 outer fold 1\n",
      "Thu Dec 12 15:36:50 2024 442/630   batch size 512\n",
      "Thu Dec 12 15:36:50 2024 442/630   max_epochs 500\n",
      "Thu Dec 12 15:36:50 2024 442/630     inner fold 0\n",
      "Thu Dec 12 15:37:21 2024 443/630     inner fold 1\n",
      "Thu Dec 12 15:38:20 2024 444/630     inner fold 2\n",
      "Thu Dec 12 15:39:06 2024 445/630     inner fold 3\n",
      "Thu Dec 12 15:39:44 2024 446/630     inner fold 4 f1_tuned: 0.669\n",
      "Thu Dec 12 15:40:43 2024 447/630   batch size 512\n",
      "Thu Dec 12 15:40:43 2024 447/630   max_epochs 1000\n",
      "Thu Dec 12 15:40:43 2024 447/630     inner fold 0\n",
      "Thu Dec 12 15:41:16 2024 448/630     inner fold 1\n",
      "Thu Dec 12 15:42:21 2024 449/630     inner fold 2\n",
      "Thu Dec 12 15:42:51 2024 450/630     inner fold 3\n",
      "Thu Dec 12 15:43:36 2024 451/630     inner fold 4 f1_tuned: 0.670\n",
      "Thu Dec 12 15:44:46 2024 452/630   batch size 1024\n",
      "Thu Dec 12 15:44:46 2024 452/630   max_epochs 500\n",
      "Thu Dec 12 15:44:46 2024 452/630     inner fold 0\n",
      "Thu Dec 12 15:45:39 2024 453/630     inner fold 1\n",
      "Thu Dec 12 15:46:42 2024 454/630     inner fold 2\n",
      "Thu Dec 12 15:47:45 2024 455/630     inner fold 3\n",
      "Thu Dec 12 15:48:38 2024 456/630     inner fold 4 f1_tuned: 0.670\n",
      "Thu Dec 12 15:49:41 2024 457/630   batch size 1024\n",
      "Thu Dec 12 15:49:41 2024 457/630   max_epochs 1000\n",
      "Thu Dec 12 15:49:41 2024 457/630     inner fold 0\n",
      "Thu Dec 12 15:50:36 2024 458/630     inner fold 1\n",
      "Thu Dec 12 15:51:28 2024 459/630     inner fold 2\n",
      "Thu Dec 12 15:52:02 2024 460/630     inner fold 3\n",
      "Thu Dec 12 15:53:06 2024 461/630     inner fold 4 f1_tuned: 0.668\n",
      "Thu Dec 12 15:54:30 2024 462/630   outer fold 1 with tuned HP f1_tuned: 0.657\n",
      "Thu Dec 12 15:55:11 2024 463/630 outer fold 2\n",
      "Thu Dec 12 15:55:11 2024 463/630   batch size 512\n",
      "Thu Dec 12 15:55:11 2024 463/630   max_epochs 500\n",
      "Thu Dec 12 15:55:11 2024 463/630     inner fold 0\n",
      "Thu Dec 12 15:55:41 2024 464/630     inner fold 1\n",
      "Thu Dec 12 15:56:17 2024 465/630     inner fold 2\n",
      "Thu Dec 12 15:57:16 2024 466/630     inner fold 3\n",
      "Thu Dec 12 15:57:57 2024 467/630     inner fold 4 f1_tuned: 0.663\n",
      "Thu Dec 12 15:58:56 2024 468/630   batch size 512\n",
      "Thu Dec 12 15:58:56 2024 468/630   max_epochs 1000\n",
      "Thu Dec 12 15:58:56 2024 468/630     inner fold 0\n",
      "Thu Dec 12 16:00:28 2024 469/630     inner fold 1\n",
      "Thu Dec 12 16:02:20 2024 470/630     inner fold 2\n",
      "Thu Dec 12 16:02:59 2024 471/630     inner fold 3\n",
      "Thu Dec 12 16:03:26 2024 472/630     inner fold 4 f1_tuned: 0.667\n",
      "Thu Dec 12 16:05:20 2024 473/630   batch size 1024\n",
      "Thu Dec 12 16:05:20 2024 473/630   max_epochs 500\n",
      "Thu Dec 12 16:05:20 2024 473/630     inner fold 0\n",
      "Thu Dec 12 16:06:22 2024 474/630     inner fold 1\n",
      "Thu Dec 12 16:07:27 2024 475/630     inner fold 2\n",
      "Thu Dec 12 16:08:14 2024 476/630     inner fold 3\n",
      "Thu Dec 12 16:09:13 2024 477/630     inner fold 4 f1_tuned: 0.663\n",
      "Thu Dec 12 16:10:15 2024 478/630   batch size 1024\n",
      "Thu Dec 12 16:10:15 2024 478/630   max_epochs 1000\n",
      "Thu Dec 12 16:10:15 2024 478/630     inner fold 0\n",
      "Thu Dec 12 16:10:58 2024 479/630     inner fold 1\n",
      "Thu Dec 12 16:12:10 2024 480/630     inner fold 2\n",
      "Thu Dec 12 16:12:58 2024 481/630     inner fold 3\n",
      "Thu Dec 12 16:14:07 2024 482/630     inner fold 4 f1_tuned: 0.664\n",
      "Thu Dec 12 16:15:35 2024 483/630   outer fold 2 with tuned HP f1_tuned: 0.647\n",
      "Thu Dec 12 16:15:55 2024 484/630 outer fold 3\n",
      "Thu Dec 12 16:15:55 2024 484/630   batch size 512\n",
      "Thu Dec 12 16:15:55 2024 484/630   max_epochs 500\n",
      "Thu Dec 12 16:15:55 2024 484/630     inner fold 0\n",
      "Thu Dec 12 16:16:52 2024 485/630     inner fold 1\n",
      "Thu Dec 12 16:17:27 2024 486/630     inner fold 2\n",
      "Thu Dec 12 16:17:57 2024 487/630     inner fold 3\n",
      "Thu Dec 12 16:18:20 2024 488/630     inner fold 4 f1_tuned: 0.669\n",
      "Thu Dec 12 16:18:46 2024 489/630   batch size 512\n",
      "Thu Dec 12 16:18:46 2024 489/630   max_epochs 1000\n",
      "Thu Dec 12 16:18:46 2024 489/630     inner fold 0\n",
      "Thu Dec 12 16:20:32 2024 490/630     inner fold 1\n",
      "Thu Dec 12 16:21:11 2024 491/630     inner fold 2\n",
      "Thu Dec 12 16:21:39 2024 492/630     inner fold 3\n",
      "Thu Dec 12 16:22:07 2024 493/630     inner fold 4 f1_tuned: 0.672\n",
      "Thu Dec 12 16:22:35 2024 494/630   batch size 1024\n",
      "Thu Dec 12 16:22:35 2024 494/630   max_epochs 500\n",
      "Thu Dec 12 16:22:35 2024 494/630     inner fold 0\n",
      "Thu Dec 12 16:23:37 2024 495/630     inner fold 1\n",
      "Thu Dec 12 16:24:13 2024 496/630     inner fold 2\n",
      "Thu Dec 12 16:24:58 2024 497/630     inner fold 3\n",
      "Thu Dec 12 16:25:37 2024 498/630     inner fold 4 f1_tuned: 0.668\n",
      "Thu Dec 12 16:26:24 2024 499/630   batch size 1024\n",
      "Thu Dec 12 16:26:24 2024 499/630   max_epochs 1000\n",
      "Thu Dec 12 16:26:24 2024 499/630     inner fold 0\n",
      "Thu Dec 12 16:28:22 2024 500/630     inner fold 1\n",
      "Thu Dec 12 16:29:10 2024 501/630     inner fold 2\n",
      "Thu Dec 12 16:29:54 2024 502/630     inner fold 3\n",
      "Thu Dec 12 16:30:25 2024 503/630     inner fold 4 f1_tuned: 0.669\n",
      "Thu Dec 12 16:31:30 2024 504/630   outer fold 3 with tuned HP f1_tuned: 0.633\n",
      "Thu Dec 12 16:31:57 2024 505/630 outer fold 4\n",
      "Thu Dec 12 16:31:57 2024 505/630   batch size 512\n",
      "Thu Dec 12 16:31:57 2024 505/630   max_epochs 500\n",
      "Thu Dec 12 16:31:57 2024 505/630     inner fold 0\n",
      "Thu Dec 12 16:32:23 2024 506/630     inner fold 1\n",
      "Thu Dec 12 16:32:51 2024 507/630     inner fold 2\n",
      "Thu Dec 12 16:33:47 2024 508/630     inner fold 3\n",
      "Thu Dec 12 16:34:19 2024 509/630     inner fold 4 f1_tuned: 0.660\n",
      "Thu Dec 12 16:34:41 2024 510/630   batch size 512\n",
      "Thu Dec 12 16:34:41 2024 510/630   max_epochs 1000\n",
      "Thu Dec 12 16:34:41 2024 510/630     inner fold 0\n",
      "Thu Dec 12 16:34:59 2024 511/630     inner fold 1\n",
      "Thu Dec 12 16:36:47 2024 512/630     inner fold 2\n",
      "Thu Dec 12 16:38:31 2024 513/630     inner fold 3\n",
      "Thu Dec 12 16:38:53 2024 514/630     inner fold 4 f1_tuned: 0.667\n",
      "Thu Dec 12 16:39:15 2024 515/630   batch size 1024\n",
      "Thu Dec 12 16:39:15 2024 515/630   max_epochs 500\n",
      "Thu Dec 12 16:39:15 2024 515/630     inner fold 0\n",
      "Thu Dec 12 16:39:52 2024 516/630     inner fold 1\n",
      "Thu Dec 12 16:40:35 2024 517/630     inner fold 2\n",
      "Thu Dec 12 16:41:37 2024 518/630     inner fold 3\n",
      "Thu Dec 12 16:42:29 2024 519/630     inner fold 4 f1_tuned: 0.660\n",
      "Thu Dec 12 16:43:36 2024 520/630   batch size 1024\n",
      "Thu Dec 12 16:43:36 2024 520/630   max_epochs 1000\n",
      "Thu Dec 12 16:43:36 2024 520/630     inner fold 0\n",
      "Thu Dec 12 16:44:22 2024 521/630     inner fold 1\n",
      "Thu Dec 12 16:45:54 2024 522/630     inner fold 2\n",
      "Thu Dec 12 16:48:04 2024 523/630     inner fold 3\n",
      "Thu Dec 12 16:48:56 2024 524/630     inner fold 4 f1_tuned: 0.661\n",
      "Thu Dec 12 16:49:47 2024 525/630   outer fold 4 with tuned HP f1_tuned: 0.681\n",
      "feature_selection: C\n",
      "relevant areas: ['area_sentinel_id_7', 'area_sentinel_id_9', 'area_sentinel_id_10']\n",
      "shape of feature matrix: (3494, 60)\n",
      "Thu Dec 12 16:50:18 2024 526/630 outer fold 0\n",
      "Thu Dec 12 16:50:18 2024 526/630   batch size 512\n",
      "Thu Dec 12 16:50:18 2024 526/630   max_epochs 500\n",
      "Thu Dec 12 16:50:18 2024 526/630     inner fold 0\n",
      "Thu Dec 12 16:51:20 2024 527/630     inner fold 1\n",
      "Thu Dec 12 16:51:40 2024 528/630     inner fold 2\n",
      "Thu Dec 12 16:52:43 2024 529/630     inner fold 3\n",
      "Thu Dec 12 16:53:29 2024 530/630     inner fold 4 f1_tuned: 0.734\n",
      "Thu Dec 12 16:54:32 2024 531/630   batch size 512\n",
      "Thu Dec 12 16:54:32 2024 531/630   max_epochs 1000\n",
      "Thu Dec 12 16:54:32 2024 531/630     inner fold 0\n",
      "Thu Dec 12 16:56:05 2024 532/630     inner fold 1\n",
      "Thu Dec 12 16:56:26 2024 533/630     inner fold 2\n",
      "Thu Dec 12 16:57:36 2024 534/630     inner fold 3\n",
      "Thu Dec 12 16:58:45 2024 535/630     inner fold 4 f1_tuned: 0.737\n",
      "Thu Dec 12 17:00:40 2024 536/630   batch size 1024\n",
      "Thu Dec 12 17:00:40 2024 536/630   max_epochs 500\n",
      "Thu Dec 12 17:00:40 2024 536/630     inner fold 0\n",
      "Thu Dec 12 17:01:43 2024 537/630     inner fold 1\n",
      "Thu Dec 12 17:02:14 2024 538/630     inner fold 2\n",
      "Thu Dec 12 17:03:17 2024 539/630     inner fold 3\n",
      "Thu Dec 12 17:04:16 2024 540/630     inner fold 4 f1_tuned: 0.728\n",
      "Thu Dec 12 17:05:18 2024 541/630   batch size 1024\n",
      "Thu Dec 12 17:05:18 2024 541/630   max_epochs 1000\n",
      "Thu Dec 12 17:05:18 2024 541/630     inner fold 0\n",
      "Thu Dec 12 17:06:57 2024 542/630     inner fold 1\n",
      "Thu Dec 12 17:07:29 2024 543/630     inner fold 2\n",
      "Thu Dec 12 17:08:41 2024 544/630     inner fold 3\n",
      "Thu Dec 12 17:09:35 2024 545/630     inner fold 4 f1_tuned: 0.732\n",
      "Thu Dec 12 17:11:21 2024 546/630   outer fold 0 with tuned HP f1_tuned: 0.736\n",
      "Thu Dec 12 17:12:58 2024 547/630 outer fold 1\n",
      "Thu Dec 12 17:12:58 2024 547/630   batch size 512\n",
      "Thu Dec 12 17:12:58 2024 547/630   max_epochs 500\n",
      "Thu Dec 12 17:12:58 2024 547/630     inner fold 0\n",
      "Thu Dec 12 17:13:24 2024 548/630     inner fold 1\n",
      "Thu Dec 12 17:14:16 2024 549/630     inner fold 2\n",
      "Thu Dec 12 17:15:13 2024 550/630     inner fold 3\n",
      "Thu Dec 12 17:16:10 2024 551/630     inner fold 4 f1_tuned: 0.730\n",
      "Thu Dec 12 17:16:51 2024 552/630   batch size 512\n",
      "Thu Dec 12 17:16:51 2024 552/630   max_epochs 1000\n",
      "Thu Dec 12 17:16:51 2024 552/630     inner fold 0\n",
      "Thu Dec 12 17:17:11 2024 553/630     inner fold 1\n",
      "Thu Dec 12 17:18:06 2024 554/630     inner fold 2\n",
      "Thu Dec 12 17:18:59 2024 555/630     inner fold 3\n",
      "Thu Dec 12 17:20:48 2024 556/630     inner fold 4 f1_tuned: 0.726\n",
      "Thu Dec 12 17:21:30 2024 557/630   batch size 1024\n",
      "Thu Dec 12 17:21:30 2024 557/630   max_epochs 500\n",
      "Thu Dec 12 17:21:30 2024 557/630     inner fold 0\n",
      "Thu Dec 12 17:22:18 2024 558/630     inner fold 1\n",
      "Thu Dec 12 17:23:17 2024 559/630     inner fold 2\n",
      "Thu Dec 12 17:24:15 2024 560/630     inner fold 3\n",
      "Thu Dec 12 17:25:13 2024 561/630     inner fold 4 f1_tuned: 0.729\n",
      "Thu Dec 12 17:26:04 2024 562/630   batch size 1024\n",
      "Thu Dec 12 17:26:04 2024 562/630   max_epochs 1000\n",
      "Thu Dec 12 17:26:04 2024 562/630     inner fold 0\n",
      "Thu Dec 12 17:26:37 2024 563/630     inner fold 1\n",
      "Thu Dec 12 17:27:53 2024 564/630     inner fold 2\n",
      "Thu Dec 12 17:29:10 2024 565/630     inner fold 3\n",
      "Thu Dec 12 17:31:01 2024 566/630     inner fold 4 f1_tuned: 0.727\n",
      "Thu Dec 12 17:31:44 2024 567/630   outer fold 1 with tuned HP f1_tuned: 0.734\n",
      "Thu Dec 12 17:32:43 2024 568/630 outer fold 2\n",
      "Thu Dec 12 17:32:43 2024 568/630   batch size 512\n",
      "Thu Dec 12 17:32:43 2024 568/630   max_epochs 500\n",
      "Thu Dec 12 17:32:43 2024 568/630     inner fold 0\n",
      "Thu Dec 12 17:33:39 2024 569/630     inner fold 1\n",
      "Thu Dec 12 17:34:33 2024 570/630     inner fold 2\n",
      "Thu Dec 12 17:35:28 2024 571/630     inner fold 3\n",
      "Thu Dec 12 17:36:23 2024 572/630     inner fold 4 f1_tuned: 0.732\n",
      "Thu Dec 12 17:37:18 2024 573/630   batch size 512\n",
      "Thu Dec 12 17:37:18 2024 573/630   max_epochs 1000\n",
      "Thu Dec 12 17:37:18 2024 573/630     inner fold 0\n",
      "Thu Dec 12 17:38:15 2024 574/630     inner fold 1\n",
      "Thu Dec 12 17:39:36 2024 575/630     inner fold 2\n",
      "Thu Dec 12 17:41:21 2024 576/630     inner fold 3\n",
      "Thu Dec 12 17:42:12 2024 577/630     inner fold 4 f1_tuned: 0.740\n",
      "Thu Dec 12 17:43:41 2024 578/630   batch size 1024\n",
      "Thu Dec 12 17:43:41 2024 578/630   max_epochs 500\n",
      "Thu Dec 12 17:43:41 2024 578/630     inner fold 0\n",
      "Thu Dec 12 17:44:10 2024 579/630     inner fold 1\n",
      "Thu Dec 12 17:45:06 2024 580/630     inner fold 2\n",
      "Thu Dec 12 17:46:01 2024 581/630     inner fold 3\n",
      "Thu Dec 12 17:46:57 2024 582/630     inner fold 4 f1_tuned: 0.721\n",
      "Thu Dec 12 17:47:53 2024 583/630   batch size 1024\n",
      "Thu Dec 12 17:47:53 2024 583/630   max_epochs 1000\n",
      "Thu Dec 12 17:47:53 2024 583/630     inner fold 0\n",
      "Thu Dec 12 17:49:37 2024 584/630     inner fold 1\n",
      "Thu Dec 12 17:51:24 2024 585/630     inner fold 2\n",
      "Thu Dec 12 17:52:59 2024 586/630     inner fold 3\n",
      "Thu Dec 12 17:54:09 2024 587/630     inner fold 4 f1_tuned: 0.735\n",
      "Thu Dec 12 17:55:20 2024 588/630   outer fold 2 with tuned HP f1_tuned: 0.734\n",
      "Thu Dec 12 17:57:11 2024 589/630 outer fold 3\n",
      "Thu Dec 12 17:57:11 2024 589/630   batch size 512\n",
      "Thu Dec 12 17:57:11 2024 589/630   max_epochs 500\n",
      "Thu Dec 12 17:57:11 2024 589/630     inner fold 0\n",
      "Thu Dec 12 17:58:05 2024 590/630     inner fold 1\n",
      "Thu Dec 12 17:58:25 2024 591/630     inner fold 2\n",
      "Thu Dec 12 17:59:16 2024 592/630     inner fold 3\n",
      "Thu Dec 12 17:59:41 2024 593/630     inner fold 4 f1_tuned: 0.727\n",
      "Thu Dec 12 18:00:32 2024 594/630   batch size 512\n",
      "Thu Dec 12 18:00:32 2024 594/630   max_epochs 1000\n",
      "Thu Dec 12 18:00:32 2024 594/630     inner fold 0\n",
      "Thu Dec 12 18:01:26 2024 595/630     inner fold 1\n",
      "Thu Dec 12 18:01:45 2024 596/630     inner fold 2\n",
      "Thu Dec 12 18:02:13 2024 597/630     inner fold 3\n",
      "Thu Dec 12 18:02:37 2024 598/630     inner fold 4 f1_tuned: 0.725\n",
      "Thu Dec 12 18:03:04 2024 599/630   batch size 1024\n",
      "Thu Dec 12 18:03:04 2024 599/630   max_epochs 500\n",
      "Thu Dec 12 18:03:04 2024 599/630     inner fold 0\n",
      "Thu Dec 12 18:03:59 2024 600/630     inner fold 1\n",
      "Thu Dec 12 18:04:55 2024 601/630     inner fold 2\n",
      "Thu Dec 12 18:05:30 2024 602/630     inner fold 3\n",
      "Thu Dec 12 18:06:26 2024 603/630     inner fold 4 f1_tuned: 0.732\n",
      "Thu Dec 12 18:07:21 2024 604/630   batch size 1024\n",
      "Thu Dec 12 18:07:21 2024 604/630   max_epochs 1000\n",
      "Thu Dec 12 18:07:21 2024 604/630     inner fold 0\n",
      "Thu Dec 12 18:08:58 2024 605/630     inner fold 1\n",
      "Thu Dec 12 18:10:21 2024 606/630     inner fold 2\n",
      "Thu Dec 12 18:11:00 2024 607/630     inner fold 3\n",
      "Thu Dec 12 18:11:51 2024 608/630     inner fold 4 f1_tuned: 0.736\n",
      "Thu Dec 12 18:12:59 2024 609/630   outer fold 3 with tuned HP f1_tuned: 0.721\n",
      "Thu Dec 12 18:14:18 2024 610/630 outer fold 4\n",
      "Thu Dec 12 18:14:18 2024 610/630   batch size 512\n",
      "Thu Dec 12 18:14:18 2024 610/630   max_epochs 500\n",
      "Thu Dec 12 18:14:18 2024 610/630     inner fold 0\n",
      "Thu Dec 12 18:15:07 2024 611/630     inner fold 1\n",
      "Thu Dec 12 18:16:00 2024 612/630     inner fold 2\n",
      "Thu Dec 12 18:16:52 2024 613/630     inner fold 3\n",
      "Thu Dec 12 18:17:46 2024 614/630     inner fold 4 f1_tuned: 0.723\n",
      "Thu Dec 12 18:18:19 2024 615/630   batch size 512\n",
      "Thu Dec 12 18:18:19 2024 615/630   max_epochs 1000\n",
      "Thu Dec 12 18:18:19 2024 615/630     inner fold 0\n",
      "Thu Dec 12 18:19:24 2024 616/630     inner fold 1\n",
      "Thu Dec 12 18:20:27 2024 617/630     inner fold 2\n",
      "Thu Dec 12 18:21:51 2024 618/630     inner fold 3\n",
      "Thu Dec 12 18:23:33 2024 619/630     inner fold 4 f1_tuned: 0.726\n",
      "Thu Dec 12 18:24:03 2024 620/630   batch size 1024\n",
      "Thu Dec 12 18:24:03 2024 620/630   max_epochs 500\n",
      "Thu Dec 12 18:24:03 2024 620/630     inner fold 0\n",
      "Thu Dec 12 18:24:57 2024 621/630     inner fold 1\n",
      "Thu Dec 12 18:25:52 2024 622/630     inner fold 2\n",
      "Thu Dec 12 18:26:46 2024 623/630     inner fold 3\n",
      "Thu Dec 12 18:27:41 2024 624/630     inner fold 4 f1_tuned: 0.721\n",
      "Thu Dec 12 18:28:22 2024 625/630   batch size 1024\n",
      "Thu Dec 12 18:28:22 2024 625/630   max_epochs 1000\n",
      "Thu Dec 12 18:28:22 2024 625/630     inner fold 0\n",
      "Thu Dec 12 18:30:07 2024 626/630     inner fold 1\n",
      "Thu Dec 12 18:31:23 2024 627/630     inner fold 2\n",
      "Thu Dec 12 18:33:08 2024 628/630     inner fold 3\n",
      "Thu Dec 12 18:34:53 2024 629/630     inner fold 4 f1_tuned: 0.727\n",
      "Thu Dec 12 18:35:46 2024 630/630   outer fold 4 with tuned HP f1_tuned: 0.750\n"
     ]
    }
   ],
   "source": [
    "### loop over compounds and feature selections\n",
    "run_count = 1\n",
    "\n",
    "for compound_name in prio_compounds[:]:\n",
    "    print('\\n', '*'*50, '\\n\\n', compound_name.upper(), '\\n')\n",
    "    \n",
    "    for feature_selection in feature_selections:\n",
    "        print('feature_selection:', feature_selection)\n",
    "        # output folder\n",
    "        output_folder = f'F:/PROJEKTE/FARM/Ephraim_Erkens/bgr-grwv/develoments_BGR/EE/output/nestedCV/{folder_name}/{compound_name}/feature_selection_{feature_selection}/'\n",
    "        for subfolder in ['data', 'models', 'fig']:\n",
    "            directory = f'{output_folder}{subfolder}/'\n",
    "            Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "        Path(f'{directory}pdp/').mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # select data (compound and features)\n",
    "        if feature_selection=='A':\n",
    "            relevant_areas = [f'area_sentinel_id_{sid}' for sid in relevant_sids[compound_name]]\n",
    "            print('relevant areas:', relevant_areas)\n",
    "            selected_columns = fs_a + relevant_areas + ['conc_group']\n",
    "            data = dfr.loc[dfr.lawa_name==compound_name, selected_columns]    \n",
    "            dff = dfr.copy()\n",
    "        if feature_selection=='C':\n",
    "            relevant_areas = [f'area_sentinel_id_{sid}' for sid in relevant_sids[compound_name]]\n",
    "            print('relevant areas:', relevant_areas)\n",
    "            selected_columns = fs_c + relevant_areas + ['conc_group']\n",
    "            data = dfa.loc[dfa.lawa_name==compound_name, selected_columns]\n",
    "            dff = dfa.copy()\n",
    "\n",
    "        # replace categorical strings by True/False for each category\n",
    "        dummy_columns = data.select_dtypes(['object', 'category']).columns\n",
    "        data = pd.get_dummies(data, columns=dummy_columns)\n",
    "        # Remove rows with any NaN values\n",
    "        data = data.dropna()\n",
    "        \n",
    "        # determine features and labels\n",
    "        y = data.pop('conc_group')\n",
    "        y = y.reset_index(drop=True) # labels\n",
    "        X = data.copy() # features\n",
    "        feature_names = X.columns.to_list()\n",
    "        # np.save(f'{path}data/{compound_name}/feature_names_{compound_name}.npy', np.array(feature_names))\n",
    "        \n",
    "        # binarize y\n",
    "        label_binarizer = LabelBinarizer()\n",
    "        one_hot_encoded_y = label_binarizer.fit_transform(y)\n",
    "        \n",
    "        # save feature names\n",
    "        feature_names = X.columns.to_list()\n",
    "        # np.save(f'{output_folder}data/feature_names.npy', np.array(feature_names))\n",
    "\n",
    "        \n",
    "        ### perform nested cross-validation\n",
    "        # importlib.reload(nn) # only needed if nn was modified\n",
    "        # performance data frame\n",
    "        performance = pd.DataFrame(columns=['compound_name', 'feature_selection', 'test_set', 'avg_time_per_fold', 'batch_size', 'max_epochs', 'outer_fold_index', 'f1_untuned', 'threshold', 'f1_tuned', 'f1_tuning_list']) \n",
    "        performance.f1_tuning_list = performance.f1_tuning_list.astype('object')\n",
    "        t_start = time.time()\n",
    "\n",
    "        print('shape of feature matrix:', X.shape)\n",
    "        \n",
    "        # save feature names\n",
    "        np.save(f'{output_folder}data/feature_names.npy', X.columns.values)\n",
    "        pd.DataFrame(feature_names).T.to_csv(f'{output_folder}data/feature_names.csv', index=False)\n",
    "        \n",
    "        # split data into outer folds\n",
    "        outer_kfold = StratifiedKFold(n_outer_folds, shuffle=True, random_state=0)\n",
    "        for outer_fold_index, (outer_train_index, outer_test_index) in enumerate(outer_kfold.split(X, y)):\n",
    "            print(time.asctime(time.localtime(time.time())), f'{run_count}/{n_runs}', 'outer fold', outer_fold_index)\n",
    "            X_outer_train = X.iloc[outer_train_index]\n",
    "            X_outer_test = X.iloc[outer_test_index]\n",
    "            y_outer_train = one_hot_encoded_y[outer_train_index]\n",
    "            y_outer_test = one_hot_encoded_y[outer_test_index]\n",
    "            mid_outer_train = dff.loc[data.index, 'messstellen_id'].reset_index().loc[outer_train_index, 'messstellen_id'] # messstellen_id\n",
    "            mid_outer_test = dff.loc[data.index, 'messstellen_id'].reset_index().loc[outer_test_index, 'messstellen_id'] # messstellen_id\n",
    "        \n",
    "            # iterate over hyperparameter combinations (grid search)\n",
    "            for batch_size in hyperparameter['batch_size'][:]:\n",
    "                for max_epochs in hyperparameter['max_epochs'][:]:\n",
    "                    print(time.asctime(time.localtime(time.time())), f'{run_count}/{n_runs}', '  batch size', batch_size)\n",
    "                    print(time.asctime(time.localtime(time.time())), f'{run_count}/{n_runs}', '  max_epochs', max_epochs)\n",
    "        \n",
    "                    inner_test_proba = pd.DataFrame(columns=['inner_fold_index', 'true_conc_group', 'probability'], dtype='float') # dataframe to save prediction probabilities for threshold optimization after iterating over all inner folds\n",
    "                    t1_inner_fold = time.time()\n",
    "                    # split data into inner folds\n",
    "                    inner_kfold = StratifiedKFold(n_inner_folds, shuffle=True, random_state=1)\n",
    "                    for inner_fold_index, (inner_train_index, inner_test_index) in enumerate(inner_kfold.split(X_outer_train, y_outer_train)):\n",
    "                        print(time.asctime(time.localtime(time.time())), f'{run_count}/{n_runs}', '    inner fold', inner_fold_index, end=' ' if inner_fold_index+1==n_inner_folds else '\\n')\n",
    "                        \n",
    "                        # binarize y\n",
    "                        label_binarizer = LabelBinarizer()\n",
    "                        y_outer_train_1hot = label_binarizer.fit_transform(y_outer_train)\n",
    "                        \n",
    "                        X_inner_train = X_outer_train.iloc[inner_train_index]\n",
    "                        X_inner_test = X_outer_train.iloc[inner_test_index]\n",
    "                        y_inner_train = y_outer_train[inner_train_index]\n",
    "                        y_inner_test = y_outer_train[inner_test_index]\n",
    "                        mid_inner_test = mid_outer_train.reset_index().loc[inner_test_index, 'messstellen_id']\n",
    "        \n",
    "                        # split train data into train and validation data\n",
    "                        X_inner_train, X_inner_val, y_inner_train, y_inner_val = train_test_split(X_inner_train, y_inner_train, test_size=0.2, random_state=2, shuffle=True, stratify=y_inner_train)\n",
    "        \n",
    "                        # Standardize features\n",
    "                        scaler = StandardScaler()\n",
    "                        X_inner_train = scaler.fit_transform(X_inner_train)\n",
    "                        X_inner_val = scaler.fit_transform(X_inner_val)\n",
    "                        X_inner_test = scaler.transform(X_inner_test)\n",
    "                        # save scaler \n",
    "                        dump(scaler, f'{output_folder}data/StdScaler_innerFold{inner_fold_index}_outerFold{outer_fold_index}.bin')\n",
    "\n",
    "                        # save data\n",
    "                        for arr, filename in zip([X_inner_train, y_inner_train, X_inner_val, y_inner_val, X_inner_test, y_inner_test], ['X_inner_train', 'y_inner_train', 'X_inner_val', 'y_inner_val', 'X_inner_test', 'y_inner_test']):\n",
    "                            np.save(f'{output_folder}data/{filename}_nCV_innerFold{inner_fold_index}_outerFold{outer_fold_index}.npy', arr)\n",
    "                            pd.DataFrame(arr).to_csv(f'{output_folder}data/{filename}_nCV_innerFold{inner_fold_index}_outerFold{outer_fold_index}.csv', index=True)\n",
    "        \n",
    "\n",
    "                        ## train model using hyperparameter selection\n",
    "                        # initialize classifier\n",
    "                        fnn = nn.FNNClassifier(input_shape=(X_inner_train.shape[1],), num_classes=n_classes, compound_name=compound_name, class_names=np.arange(n_classes)+1)\n",
    "                        # build model\n",
    "                        fnn.build_model()\n",
    "                        # train model\n",
    "                        fnn.train(\n",
    "                            X_inner_train,\n",
    "                            y_inner_train,\n",
    "                            X_inner_val,\n",
    "                            y_inner_val,\n",
    "                            batch_size=batch_size,\n",
    "                            max_epochs=max_epochs\n",
    "                        )\n",
    "                        # save model\n",
    "                        fnn.model.save(f'{output_folder}models/fnn_nCV_innerFold{inner_fold_index}_outerFold{outer_fold_index}.keras')\n",
    "                        # np.save(f'{output_folder}models/cm_nCV_innerFold{inner_fold_index}_outerFold{outer_fold_index}.npy', fnn.confusion)\n",
    "                        \n",
    "                        # make predictions\n",
    "                        proba = fnn.model.predict(X_inner_test, verbose=0)\n",
    "                        inner_fold_proba = pd.DataFrame(columns=['messstellen_id', 'inner_fold_index', 'true_conc_group', 'probability', 'pred_conc_group_untuned', 'pred_conc_group_tuned'])\n",
    "                        inner_fold_proba.true_conc_group = y_inner_test.reshape(-1)\n",
    "                        inner_fold_proba.probability = proba.reshape(-1)\n",
    "                        inner_fold_proba.inner_fold_index = inner_fold_index\n",
    "                        inner_fold_proba.pred_conc_group_untuned = (inner_fold_proba.probability>=.5).astype('int')\n",
    "                        inner_fold_proba.messstellen_id = mid_inner_test\n",
    "                        # add prediction probabilities to data frame\n",
    "                        inner_test_proba = pd.concat([inner_test_proba if not inner_test_proba.empty else None, inner_fold_proba], ignore_index=True)\n",
    "                        run_count += 1\n",
    "        \n",
    "                    # calculate f1-score before threshold tuning\n",
    "                    f1_untuned = f1_score(inner_test_proba.true_conc_group.values, inner_test_proba.pred_conc_group_untuned.values, pos_label=1, average='macro')\n",
    "                    \n",
    "                    ## optimize threshold\n",
    "                    thresholds = np.arange(0, 1.01, 0.01)\n",
    "                    f1_scores_tuning = []\n",
    "                    for t in thresholds:\n",
    "                        y_pred_t = (inner_test_proba.probability>=t).astype('int')\n",
    "                        f1_t = f1_score(inner_test_proba.true_conc_group.values, y_pred_t, pos_label=1, average='macro')\n",
    "                        f1_scores_tuning.append(f1_t)\n",
    "                    # find highest f1-score after threshold tuning\n",
    "                    i_maxf1 = np.argmax(f1_scores_tuning)\n",
    "                    threshold_tuned = thresholds[i_maxf1]\n",
    "                    f1_tuned = f1_scores_tuning[i_maxf1]\n",
    "                    print(f'f1_tuned: {f1_tuned:.3f}')\n",
    "                    inner_test_proba.pred_conc_group_tuned = (inner_test_proba.probability>=threshold_tuned).astype('int')\n",
    "                    # safe predictions\n",
    "                    inner_test_proba.to_csv(f'{output_folder}data/predictions_innerFoldsCombined_outerFold{outer_fold_index}.csv', index=False)\n",
    "                    \n",
    "                    cm_tuned = confusion_matrix(inner_test_proba.true_conc_group, inner_test_proba.pred_conc_group_tuned)\n",
    "                    # safe confusion matrix of tuned predictions\n",
    "                    pd.DataFrame(cm_tuned, columns=['1_pred', '2_pred'], index=['1_true', '2_true']).to_csv(f'{output_folder}data/cm_stacked_innerFoldsCombined_outerFold{outer_fold_index}.csv', index=True)\n",
    "        \n",
    "                    # time per inner fold\n",
    "                    t2_inner_fold = time.time()\n",
    "                    t_inner_fold = (t2_inner_fold-t1_inner_fold)/n_inner_folds\n",
    "            \n",
    "                    # save performance measures (f1-score etc.)\n",
    "                    fold_performance = dict(compound_name=compound_name, feature_selection=feature_selection, test_set='inner_combined', batch_size=batch_size, max_epochs=max_epochs, outer_fold_index=outer_fold_index, f1_untuned=f1_untuned, threshold_tuned=threshold_tuned, f1_tuned=f1_tuned, f1_tuning_list=None, avg_time_per_fold=t_inner_fold)\n",
    "                    fold_performance = pd.DataFrame(fold_performance, index=[0])\n",
    "                    performance = pd.concat([performance if not performance.empty else None, fold_performance], ignore_index=True)\n",
    "                    performance.f1_tuning_list = performance.f1_tuning_list.astype('object')\n",
    "                    performance.at[performance.index[-1], 'f1_tuning_list'] = f1_scores_tuning\n",
    "        \n",
    "            t1_outer_fold = time.time()\n",
    "                        \n",
    "            # compare performance measure and get best hyperparameter combination and corresponding threshold\n",
    "            best_batch_size = performance.loc[performance[performance.outer_fold_index==outer_fold_index].f1_tuned.idxmax(), 'batch_size']\n",
    "            best_max_epochs = performance.loc[performance[performance.outer_fold_index==outer_fold_index].f1_tuned.idxmax(), 'max_epochs']\n",
    "            best_threshold = performance.loc[performance[performance.outer_fold_index==outer_fold_index].f1_tuned.idxmax(), 'threshold_tuned']\n",
    "        \n",
    "            # split train data into train and validation data\n",
    "            X_outer_train, X_outer_val, y_outer_train, y_outer_val = train_test_split(X_outer_train, y_outer_train, test_size=0.2, random_state=42, shuffle=True, stratify=y_outer_train)\n",
    "        \n",
    "            # Standardize features\n",
    "            scaler = StandardScaler()\n",
    "            X_outer_train = scaler.fit_transform(X_outer_train)\n",
    "            X_outer_val = scaler.transform(X_outer_val)\n",
    "            X_outer_test = scaler.transform(X_outer_test)\n",
    "            # save scaler \n",
    "            dump(scaler, f'{output_folder}data/StdScaler_outerFold{outer_fold_index}.bin')\n",
    "\n",
    "            # save data\n",
    "            for arr, filename in zip([X_outer_train, y_outer_train, X_outer_val, y_outer_val, X_outer_test, y_outer_test], ['X_outer_train', 'y_outer_train', 'X_outer_val', 'y_outer_val', 'X_outer_test', 'y_outer_test']):\n",
    "                np.save(f'{output_folder}data/{filename}_nCV_outerFold{outer_fold_index}.npy', arr)\n",
    "                pd.DataFrame(arr).to_csv(f'{output_folder}data/{filename}_nCV_outerFold{outer_fold_index}.csv', index=True)\n",
    "     \n",
    "            print(time.asctime(time.localtime(time.time())), f'{run_count}/{n_runs}', '  outer fold', outer_fold_index, 'with tuned HP', end=' ')\n",
    "            # train outer fold with best hyperparameter combination\n",
    "            fnn = nn.FNNClassifier(input_shape=(X_inner_train.shape[1],), num_classes=n_classes, compound_name=compound_name, class_names=np.arange(n_classes)+1)\n",
    "            fnn.build_model()\n",
    "            fnn.train(\n",
    "                X_outer_train,\n",
    "                y_outer_train,\n",
    "                X_outer_val,\n",
    "                y_outer_val,\n",
    "                batch_size=best_batch_size,\n",
    "                max_epochs=best_max_epochs\n",
    "            )\n",
    "            # evaluate performance\n",
    "            fnn.evaluate(\n",
    "                X_outer_test,\n",
    "                y_outer_test,\n",
    "                # threshold=best_threshold\n",
    "            )\n",
    "            # safe model\n",
    "            fnn.model.save(f'{output_folder}models/fnn_nCV_outerFold{outer_fold_index}.keras')\n",
    "            # np.save(f'{output_folder}models/cm_nCV_outerFold{outer_fold_index}.npy', fnn.confusion)\n",
    "            \n",
    "            \n",
    "            proba = fnn.model.predict(X_outer_test, verbose=0)\n",
    "            y_predicted = np.array([1 if x >= 0.5 else 0 for x in proba])\n",
    "            f1_untuned = f1_score(y_outer_test, y_predicted, pos_label=1, average='macro')\n",
    "            y_predicted_bestThresh = np.array([1 if x >= best_threshold else 0 for x in proba])\n",
    "            f1_tuned = f1_score(y_outer_test, y_predicted_bestThresh, pos_label=1, average='macro')\n",
    "            print(f'f1_tuned: {f1_tuned:.3f}')\n",
    "\n",
    "            # safe predictions\n",
    "            outer_test_proba = pd.DataFrame(columns=['messstellen_id', 'outer_fold_index', 'true_conc_group', 'probability', 'pred_conc_group_untuned', 'pred_conc_group_tuned', 'used_best_threshold', 'pred_conc_group_tuned_new', 'tuned_threshold_new_unused'])\n",
    "            outer_test_proba.outer_fold_index = outer_fold_index\n",
    "            outer_test_proba.true_conc_group = y_outer_test.reshape(-1)\n",
    "            outer_test_proba.probability = proba\n",
    "            outer_test_proba.pred_conc_group_untuned = y_predicted\n",
    "            outer_test_proba.pred_conc_group_tuned = y_predicted_bestThresh\n",
    "            outer_test_proba.used_best_threshold = best_threshold\n",
    "            outer_test_proba.messstellen_id = mid_outer_test\n",
    "                    \n",
    "            cm_tuned = confusion_matrix(inner_test_proba.true_conc_group, inner_test_proba.pred_conc_group_tuned)\n",
    "            # safe confusion matrix of tuned predictions\n",
    "            pd.DataFrame(cm_tuned, columns=['1_pred', '2_pred'], index=['1_true', '2_true']).to_csv(f'{output_folder}data/cm_stacked_outerFold_outerFold{outer_fold_index}.csv', index=True)\n",
    "        \n",
    "            # new threshold tuning (just for comparison)\n",
    "            f1_scores_tuning = []\n",
    "            for t in thresholds:\n",
    "                y_pred_t = np.array([1 if x >= t else 0 for x in proba])\n",
    "                f1_t = f1_score(y_outer_test, y_pred_t, pos_label=1, average='macro')\n",
    "                f1_scores_tuning.append(f1_t)\n",
    "            i_max_f1 = np.argmax(f1_scores_tuning)\n",
    "            tuned_threshold_new_unused = thresholds[i_max_f1]\n",
    "            y_pred_new = np.array([1 if x >= tuned_threshold_new_unused else 0 for x in proba])\n",
    "\n",
    "            outer_test_proba.pred_conc_group_tuned_new = y_pred_new\n",
    "            outer_test_proba.tuned_threshold_new_unused = tuned_threshold_new_unused\n",
    "            outer_test_proba.to_csv(f'{output_folder}data/predictions_outerFold_outerFold{outer_fold_index}.csv', index=False)\n",
    "        \n",
    "            t2_outer_fold = time.time()\n",
    "            t_outer_fold = t2_outer_fold-t1_outer_fold\n",
    "            \n",
    "            # save performance measures (f1-score etc.)\n",
    "            fold_performance = dict(compound_name=compound_name, feature_selection=feature_selection, test_set='outer', batch_size=best_batch_size, max_epochs=best_max_epochs, outer_fold_index=outer_fold_index, f1_untuned=f1_untuned, threshold_tuned=best_threshold, f1_tuned=f1_tuned, f1_tuning_list=None, avg_time_per_fold=t_outer_fold) \n",
    "            fold_performance = pd.DataFrame(fold_performance, index=[0])\n",
    "            performance = pd.concat([performance if not performance.empty else None, fold_performance], ignore_index=True)\n",
    "            performance.f1_tuning_list = performance.f1_tuning_list.astype('object')\n",
    "            performance.at[performance.index[-1], 'f1_tuning_list'] = f1_scores_tuning\n",
    "        \n",
    "            run_count += 1\n",
    "        \n",
    "        t_end = time.time()\n",
    "        \n",
    "        # safe performance data frame\n",
    "        performance.to_csv(f'{output_folder}performances.csv', index=False)\n",
    "        \n",
    "        # print(f'total time: {(t_end-t_start)/n_runs} seconds')\n",
    "        # print(f'average time per model run: {(t_end-t_start)/n_runs:.0f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
